## 论文

### Cache Aware Instruction Accurate Simulation of a 3-D Coastal Ocean Model on Low Power Hardware

```
Schoenwetter D, Ditter A, Aizinger V, et al. Cache aware instruction accurate simulation of a 3-D coastal ocean model on low power hardware[C]//2016 6th International Conference on Simulation and Modeling Methodologies, Technologies and Applications (SIMULTECH). IEEE, 2016: 1-9.
```

```
在本文中，我们研究和改进了 OVP 的基本指令精确仿真技术，以便在应用程序的运行时预测方面获得更准确的结果。我们的结果表明，通过使用特定于硬件的缓存模型，可以显着增强最先进的指令精确模拟。这是以很少的额外运行时间开销提高硬件仿真准确性的重要的第一步。这一点尤其重要，因为未来软件系统的模拟的复杂性和执行时间预计将稳步增加。此外，模拟的复杂性随着模拟软件和硬件的复杂性和大小呈指数增长。我们使用 NAS Parallel Benchmark 套件，这是一组单独的串行和并行内核，其中包含与 HPC 域中的应用程序类相对应的广泛且具有代表性的应用程序集，以量化我们的缓存模型提供的改进。使用真实世界的应用程序 UTBEST3D 证实了这些发现。作为下一步，我们将开发和分析统计管道模型对模拟准确性的影响。由于建模阶段每增加一个精度级别都对应于模拟运行时的额外开销，我们的目标是找到模拟精度和运行时间之间的最佳点。
```

### A Review of ARM Processor Architecture  History, Progress and Applications

```
Asghar M N. A Review of ARM Processor Architecture History, Progress and Applications[J]. Journal of Applied and Emerging Sciences, 2020, 10(2): pp 171-179.
```

```
自2014年以来，全球有超过500亿个基于ARM架构的32位和64位指令集架构的嵌入式芯片在数量上被普遍使用和生产。在我们的日常生活中，大多数人使用并依赖于电和汽车设备，现在已成为他们日常生活中必不可少的一部分。由于这个原因，嵌入式处理器被用于构建这样的设备，它们占用更少的硅胶空间、提供高效的处理和更少的功率。ARM 架构融合了简单的硬件指令集，这些指令集被困在 RISC 理念中，但又让人想起了一些关键的 CISC 功能，例如改进的代码密度，使 ARM 更节能，并导致硅尺寸更小。它是一种简单的流水线结构，成本低，并为现代 VLSI 技术和嵌入式应用程序增加了效率，这些技术允许系统的大量其他组件可以合并到同一芯片上。当前的低端 ARM 内核是 ARM9TDMI，它被一系列应用程序过度使用，并且还支持 ARM 32 位和 16 位 Thumb 指令集，允许用户在高代码密度和高性能之间进行权衡。作为我们日常生活一部分的大多数智能手机和电子产品现在都在使用这种电源。面向 ARM9 的 ARM 处理器使用 5 个阶段的流水线，例如：获取、解码、执行、数据存储器访问和寄存器写入。
```

### Regional Ocean Model Parallel Optimization in “Sunway Tai hu Light”

```
Wu Q, Ni Y, Huang X. Regional Ocean Model Parallel Optimization in “Sunway TaihuLight”[J]. Journal of Computer Research and Development, 2019, 56(7): 1556.
```

```
海洋模式作为地球数值模拟中重要的组成模块,在很多领域都起到了至关重要的作用,不仅是研究海洋、河口和海岸不可或缺的科研手段,基于海洋模式搭建的预报系统还能够实时预测台风、海啸等现象.为了模拟更细粒度的海洋变化，海洋模式朝着更高的分辨率和更多的物理参数化方案发展,一
般的计算机已无法满足其需求.随着散热和功耗成为通用处理器的主要瓶颈，多核、众核以及由此导致的异构已成为下一代超级计算机的发展趋势，这也为发展高分辨率海洋模式提供了坚实的基础平台.基于国产超级计算机“神威●太湖之光”，利用其异构众核体系结构的优势对普林斯顿海洋模式( Princeton ocean model, POM)进行移植和优化,从而充分发挥了国产异构众核平台的特点和优势.基于神威的高分辨率海洋模式swPOM( Sunway Princeton ocean model)在主从核协作下运行效率达到纯主核的13倍,是通用Intel平台的2.8倍左右，可扩展到25万核上运行，为实时预报系统提供了保障。
```

### Evaluating the Performance of Kunpeng 920 Processors on Modern HPC Applications

```
Afanasyev I, Lichmanov D. Evaluating the Performance of Kunpeng 920 Processors on Modern HPC Applications[C]//International Conference on Parallel Computing Technologies. Springer, Cham, 2021: 301-321.
```

```
如今，ARM 处理器广泛用于各种 HPC 应用。随着 ARM 的迅速普及，仍然严重缺乏对此类系统在各种工作负载上的详细性能评估。与其他现有的性能评估方法不同，本文介绍了创建完整和全面的基准测试集的方法，这使我们能够详细介绍鲲鹏 920–6426 和英特尔至强 6140 处理器的性能比较。开发的基准测试基于相对简单的代码片段，经常用于许多科学和现实世界的应用程序中。对于每个基准，我们基于自上而下和屋顶线性能模型提供详细的可扩展性和性能分析，从而可以识别每个基准的瓶颈和实施效率。评估结果表明，鲲鹏 920 在各种缓存绑定和内存绑定应用程序（例如模板内核、密集矩阵和向量操作）上的性能优于英特尔至强 6140 处理器。同时，鲲鹏 920 在计算密集型问题上表现出较低的性能，这些问题可以向量化或涉及间接内存访问的问题，例如图形算法。

在本文中，我们提出了一个基准测试系统，旨在比较鲲鹏 920 和英特尔至强 6140 处理器的性能。根据进行的研究，鲲鹏 920 处理器在各种内存绑定应用程序上表现出更高的性能，包括 1D、2D 和 3D 模板内核、lcopt 基准测试、密集向量操作、矩阵转置。此外，鲲鹏 920 还允许在标量计算绑定问题上实现更高的性能，例如随机数生成或 N 体问题。同时，鲲鹏 920 在可向量化计算密集型应用程序（例如 HPL）或涉及对大型数组的间接内存访问或大跨度的跨步内存访问的算法上表现出较低的性能，如多图算法和随机访问基准。
```

### Porting the LHCb Stack from x86 (Intel) to aarch64 (ARM)

```
Promberger L. Porting the LHCb Stack from x86 (Intel) to aarch64 (ARM)[R]. 2018.
```

```
将LHCb堆栈从x86(Intel)移植到aarch64(ARM)
```

### Efficiency Modeling and Analysis of 64-bit ARM Clusters for HPC

```
Weloli J W, Bilavarn S, Derradji S, et al. Efficiency Modeling and Analysis of 64-bit ARM Clusters for HPC[C]//2016 Euromicro Conference on Digital System Design (DSD). IEEE, 2016: 342-347.
```

```
本文研究了使用ARM 64位内核来提高即将到来的高性能计算系统的处理效率。它描述了一组可用的工具、模型和平台，以及它们在一种有效的方法中的组合，用于大型多核计算集群的设计空间探索。使用代表性基准的实验和结果允许设置一种探索方法，以评估微体系结构级别的基本设计选项，同时使用大量核心进行扩展，并设想未来系统分析和改进的第一方向。

在本文中，我们详细研究了如何结合使用相关模型、工具、平台和基准来定义一种健壮的设计空间探索方法，以适应即将到来的HPC严格的处理效率限制，特别是在ARMv8 64位内核提供的新视角下。适当的体系结构探索被分解为两个步骤，这两个步骤允许i)在节点/群集级进行可靠的建模和仿真，以及ii)使用ARMv8核心模型对中等数量的节点进行可扩展性分析。已报道的实验和结果表明，该方法能够可靠地研究中心设计参数，即在FLOPS性能和效率、高速缓存和存储器层次以及支持多达48个节点的可扩展性方面。目前正在对电力模型进行进一步的可伸缩性和评估，以扩展现有的方法，以支持对能源效率的大幅提高进行精细分析。从那时起，未来的工作将能够集中在节点、集群、内存父级、互连和可伸缩性层面上对不同的微结构机会进行评估和全面分析。
```

### An Empirical Study of HPC Workloads on Huawei  Kunpeng Arm-based Processor

```
Wang Y C, Chen J K, Li B R, et al. An empirical study of hpc workloads on huawei kunpeng 916 processor[C]//2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS). IEEE, 2019: 360-367.
```

```
国内有相关研究者较早地评估了第一代华为鲲鹏 916 芯片面向 HPC 的发展趋势。文章为了评估该芯片的计算潜力，使用了三种基准（HPL、STREAM、LMbench）、三种典型的科学内核（SpMV，N-body，GEMM）、三种广泛使用的微型应用程序（TeaLeaf，Neutral 和 SNAP）和实际应用（GTC-P）比较了鲲鹏916 和 Intel Xeon E5-2680v3/4（Haswell/Broadwell）的性能结果。文章指出鲲鹏916 在内存带宽上占据优势，在运行内存绑定的 HPC 应用程序中性能较为突出。
```

### Kunpeng 920: The First 7-nm Chiplet-Based 64-Core ARM SoC for Cloud Services

```
Xia J, Cheng C, Zhou X, et al. Kunpeng 920: The First 7-nm Chiplet-Based 64-Core ARM SoC for Cloud Services[J]. IEEE Micro, 2021, 41(5): 67-75.
```

```
```

### Improving ocean modeling software NEMO 4.0 benchmarking and communication efficiency

```
Irrmann G, Masson S, Maisonnave É, et al. Improving ocean modeling software NEMO 4.0 benchmarking and communication efficiency[J]. Geoscientific Model Development, 2022, 15(4): 1567-1582.
```

```

```

### On the performance of a highly-scalable Computational Fluid Dynamics code on AMD, ARM and Intel processor-based HPC systems

```
Ouro P, Lopez-Novoa U, Guest M F. On the performance of a highly-scalable Computational Fluid Dynamics code on AMD, ARM and Intel processor-based HPC systems[J]. Computer Physics Communications, 2021, 269: 108105.
```

```
没有哪个计算领域比高性能计算(HPC)更渴求性能，高性能计算的需求仍然是处理器性能和加速器采用的主要驱动力，也是内存、存储和网络技术的进步。英特尔处理器在过去十年中占据主导地位的一个关键特征是广泛采用GPU作为协处理器，而最近的发展看到了许多CPU处理器的可用性增加，包括基于ARM的新型芯片。本文分析了最先进的计算流体动力学(CFD)代码在两个高性能计算集群系统上的性能和可扩展性：配备了AMD EPYC-Roma(EPYC，4096核)和Intel Skylake(SKL，8000核)处理器和Infiniband EDR互连的Hawk；以及配备了基于ARM的Marvell ThunderX2(TX2,8192核)和Cray Aries互连的Isambard。分析了三种数值复杂度不断增加的基准情形，即采用四阶中心差分的盖子驱动空腔流动，用五阶WENO格式求解Taylor-Green涡旋，以及用Level Set方法和WENO格式计算行波孤立波；在单节点或多节点上设计了较大计算与通信比的问题规模。我们的结果表明，EPYC集群为所考虑的所有设置提供了最佳的代码性能。在前两个基准测试中，SKL集群表现出比TX2系统更快的计算时间，而在孤立波模拟中，TX2集群获得了良好的可扩展性和与EPYC系统相似的性能，两者都比SKL集群的性能有所改善。这些结果表明，虽然英特尔SKL核心提供了最好的强大可扩展性，但与EPYC系统相比，相关的群集性能较低。考虑到最近加入HPC产品组合，TX2群集的性能前景看好。

本文比较了Intel Skylake(SKL)、ARMv8.1 ThunderX2(TX2)和AMD EPYC-Roman(EPYC)这三种具有独特节点体系结构的集群系统在基于最先进的内部计算流体动力学(CFD)程序--HY3D的应用程序中的性能。这项研究调查了代码在单节点和多节点性能上的弱可伸缩性，在包含几个问题大小的三个基准测试中具有强大的可伸缩性，并使用了多达8,000个内核。所考虑的基准情况是盖子驱动的空腔流动、Taylor-Green涡和孤立波在数值水池中的传播，这些都是为了进行日益困难和昂贵的计算而设计的。计算工作量不同，前两种情况的对流通量计算分别采用四阶中心差分格式和五阶WENO格式，而在波浪模拟中，水平集方法方程的计算也采用五阶WENO格式。无论问题大小，基于EPYC的系统为所有基准测试案例提供了最快的计算时间，这归因于与40核SKL节点相比，每个节点有64个内核，并且时钟频率比TX2处理器更高。当通信开销显著增加时，小问题规模的TX2性能具有次优的强可伸缩性。然而，增加网格单元的数量减少了TX2和SKL之间的差异，两者都显示出类似的运行时值，尽管这些值比使用EPYC处理器获得的值更大。对于孤立波情况，TX2在所有问题大小上都比SKL处理器获得了更好的计算性能。尽管如此，在大多数情况下，一个值得注意的特点是，在TX2上，特别是当网格单元的数量相对较少时，需要提高其在TX2上的强大可伸缩性，这是由于阻止MPI通信的开销造成的。

这项研究表明，采用高阶WENO格式的主要缺点是，与中心差分相比，它们的计算开销更大。结果表明，在采用WENO方案的仿真中，该码在TX2上的性能与在SKL处理器上的性能相似。这表明，在依赖网格连通性和大模板的非结构网格中使用有限体积或有限元的CFD程序在运行在TX2处理器上时可以获得良好的性能，因为这样的格式在计算上比中心差分要求更高。HPC和CFD社区对这里显示的结果很感兴趣，无论是那些从事计算成本极高的直接数值和大涡模拟应用程序的人，还是那些进行面向工程的模拟的人。本文的研究是基于结构网格CFD程序的性能，使用中心差分作为广泛使用的数值格式来计算大涡模拟和数值模拟中的粘性通量和对流通量。考虑到针对HPC的ARM生态系统的成熟度，我们注意到，在TX2系统上编译或运行，无需修改代码库。这些测试中使用的Cray编译器和其他性能工具，例如分析器和调试器，显示了产品级的成熟度。从用户的角度来看，它们提供了与其他商业HPC工具类似的界面，并且在使用过程中没有出现任何问题或错误。未来的工作将集中在这些系统的能源使用上。目前的研究集中在原始计算时间上，但能源效率在高性能计算领域越来越受到关注，这将通过FLOP/s和WATS之间的平衡来探讨。
```

### Performance of Devito on HPC-Optimised ARM Processors-small

```
Senger H, Freire J, Gomi E, et al. Performance of Devito on HPC-Optimised ARM Processors[J]. Memory, 8(6): 6.
```

```
在这项工作中，我们评估了Devito，一种域特定语言(DSL)在ARM ThunderX2处理器上的性能。使用两个常见的地震计算内核进行的实验表明，与Intel Xeon处理器相比，ARM处理器可以获得与之相当的性能。

HPC优化的ARM处理器HPC优化的ARM处理器正在涌现：华为(鲲鹏920)、安培(EMag)、富士通(A64FX)和Marvell(ThunderX2)。在最近的研究中，基于ARM的超级计算机已经证明能够提供与最先进的HPC优化处理器(例如Intel Skylake和Broadwell)相媲美的性能水平，适用于各种应用程序，具有非常诱人的性价比。Isambard系统-欧洲最大的基于ARM的HPC生产系统：
 Cray XC50 (Scout) with Aries interconnect
 Each node has 2 Arm based processors-32-core
 Marvell ThunderX2 CPUs, 256 GB of DDR4 DRAM
 42 blades with 4 nodes
 The whole system: 10,752 Armv8 cores

DeVito是一种有限差分DSL，用于从基于SymPy的简明符号表达式创建高度优化的有限差分运算符。创建运算符象征性地允许应用程序开发人员：
 Build complex solvers from a few lines of code
 Utilise automated (symbolic, and loop) performance optimisation
 Adjust numerical discretization at run time
 To develop and integrate other mathematical operators that fall outside the stencil programming model
 Develop high-performance solvers in hours, not months
目前，并行性由集成到Devito编译器堆栈的OpenMP和MPI支持。针对GPU的代码生成正在开发中。

主要发现：
 有了Devito，基于ARM的处理器能够提供与最先进的Intel Xeon处理器类似的性能来执行地震反问题。
 Devito被证明能够为ARM处理器生成高效的高性能代码。
 所有型号都成功编译和运行，除了指定编译器及其选项外，无需特定于体系结构的代码调整即可获得高性能。
```

### 面向ARM高性能处理器的模板计算性能优化研究

```
冯璐霞. 面向 ARM 高性能处理器的模板计算性能优化研究[D]. 国防科学技术大学, 2016.
```

```
https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFDTEMP&filename=1018998094.nh
```

### 面向 ARM64 架构多核微处理器的模板计算性能优化研究

```
冯璐霞, 李春江, 黄亚斌. 面向 ARM64 架构多核微处理器的模板计算性能优化研究[J]. 计算机工程与科学, 2017, 39(5): 829-833.
```

```
为了提升模板计算在 ARM 处理器的性能，冯路霞等人提出了基于两维度绑定的模板计算优化方法。该方法通过线程与 CPU 绑定和线程与数据块绑定来减少线程调度开销，增加缓存命中率，实验结果在 ARM 架构下表现出较好的可扩展性。
```

### 解读“暴力”的 AI 芯片昇腾 910

```
黄海峰. 徐直军解读“暴力”的 AI 芯片昇腾 910[J]. 通信世界, 2019(24). 
```

```

```

### 基于国产处理器架构的高能物理数据处理系统

```
程耀东, 程垚松, 毕玉江, 等. 基于国产处理器架构的高能物理数据处理系统[J]. 大数据, 7(5): 2021046.
```

```
随着规模的不断扩大，高能物理实验产生了越来越多的科学数据，迫切需要先进的数据处理系统来支撑科学研究。目前，以ARM架构等为代表的国产处理器发展迅速，高能物理数据处理系统面临着新的机遇与挑战。首先总结了高能物理数据处理系统的需求及体系架构；然后描述了在国产处理器上开展的高能物理数据处理软件移植等相关工作，并提出了一种新的面向高能物理数据处理的可计算存储技术方案；最后给出了在国产处理器架构上的典型应用评测结果。

本文基于ARM国产处理器及服务器等硬件，构建了完整的高能 物理数据处理系统，包括EOS等数据存储软件、HTCondor等作业调度软件、ROOT/GEANT等基础软件库、LHAASO/LQCD等应用软件，并实现了大规模的运行。同时，本文还从超大数据处理挑战出发，提出了可计算存储技术方案，有效地解决了计算过程中因数据搬运带来的I/O瓶颈问题。LHAASO事例重建与解码等典型应用评测结果说明，基于国产处理架构的高能物理数据处理系统运行正确，多核架构的整机性能突出。可计算存储方式能够有效地利用存储节点的硬件能力，实现典型计算任务的卸载，避免数据多次搬运，提高计算效率。目前，本系统已经支持典型的高能物理应用，证明了在国产处理器架构上开展高能物理数据处理的可行性和可推广性。下一步，将移植和优化更多的应用，基于可计算存储技术架构实现更多的计算任务卸载，并进一步将经验推广到其他相关领域。
```

### 基于采样尺度自适应的多尺度量子谐振子优化算法并行化

```
焦育威, 王鹏, 辛罡. 基于采样尺度自适应的多尺度量子谐振子优化算法并行化[J]. 计算机工程与科学, 2021.
```

```

```

### Direct Numerical Simulation of Stratified Turbulent Flows and Passive Tracer Transport on HPC Systems: Comparison of CPU Architectures

```
Mortikov E V, Debolskiy A V. Direct Numerical Simulation of Stratified Turbulent Flows and Passive Tracer Transport on HPC Systems: Comparison of CPU Architectures[J]. Supercomputing Frontiers and Innovations, 2021, 8(4): 50-68.
```

```
高性能计算系统分层湍流和被动示踪剂输运的直接数值模拟：CPU结构的比较

	在本文中，我们评估了高性能计算系统中常用的CPU体系结构对用于湍流直接数值模拟(DNS)的算法执行效率的影响。我们把稳定分层的湍流平面Couette流作为一个基准问题，并补充了被动物质的额外输运。对比包括 Intel Xeon、AMD Rome x86 CPU 和 huawei kunpeng ARM CPU。我们讨论了面向内存的优化在每个平台上实现示踪剂传输的效率方面的作用。
	目前，地球物理湍流的数值模拟仍然是最具挑战性的计算问题之一。大型复杂气候和天气预报模式、湍流动力学物理研究和工程计算流体力学(CFD)应用属于所有高性能计算中心的首要任务。所有这些问题都涉及到从著名的Navier-Stokes方程组获得的流体动力学方程的数值解，并对具体问题进行了额外的简化。
	虽然大量的科学文献(据作者所知是轻描淡写的)致力于开发高效的数值方法，解决CFD问题的算法，但亿级计算的出现提出了新的和持续的挑战：常用的和众所周知的方法在多大程度上适合当前和下一代HPC系统？主要挑战与超级计算机中使用或预期使用的内存和计算方面的大规模并发和高度异构性环境有关，这是由于开发更节能和计算效率更高的硬件造成的。即使是经常考虑的用于解决CFD应用中的广泛问题的算法，例如，FFT或多重网格方法，也可能需要对这种高性能计算体系结构进行重新表述和优化。
	尽管超级计算机在过去几十年中的一个显著发展是协处理器的出现，例如基于GPU的计算，但更新的构建HPC系统的方法与基于ARM的CPU相关，这些CPU的设计将能效考虑放在了首位。这些考虑因素本质上与受功耗高度限制的大规模HPC系统所能实现的计算性能相联系。在这方面一个值得注意的例子是RIKEN计算科学中心配备基于ARM的A64FX 48C 2.2 GHz CPU的Fugaku超级计算机，它在2021年6月的TOP500最快高性能计算系统排行榜上名列前茅。
	本文以湍流的直接数值模拟(DNS)作为计算基准，比较了Intel Xeon Gold、AMD Roman和基于ARM的华为鲲鹏920三种不同架构的CPU的性能。湍流的直接数值模拟意味着对Navier-Stokes方程组的数值解，因此需要将湍流运动的所有能量显著尺度分解到发生能量耗散的最小尺度。虽然LES(大涡模拟)和RANS(雷诺平均Navier-Stokes)模式可以用来研究大尺度(直到行星尺度)的流动，但它们依赖额外的湍流闭合假设来表示归因于小尺度的动量、热量和其他标量通量，这些通量不是在计算网格上解析的，或者不被排除在粗略物理模式本身之外。相反，尽管以很高的计算代价为代价，但数值模式没有这样的假设，并且为深入了解湍流动力学、发展RAN和LES湍流模式和参数化提供了宝贵的数据。对于地球物理湍流，dns的这些高计算要求尤为明显。例如，考虑雷诺数Re可以得到一个粗略的估计，雷诺数Re代表最大和最小运动尺度的比率，在大气和海洋边界层中可能达到107-109左右的值。三维湍流的计算网格的大小为Re9/4，这表明当考虑到运动方程的时间相关性并假设算法的线性计算复杂性(就网格单元的数量而言)时，雷诺数的加倍几乎增加了计算成本一个数量级。为了正确地认识这一点，例如，对于Re值超过105和可行的计算时间框架，需要大约103个CPU核心的湍流通道流动的数值模拟，例如，参见。
	本文考虑的计算基准是基于稳定分层的平面Couette流，它被广泛用于湍流动力学研究和为大尺度大气和海洋模式开发的湍流闭合的验证。Couette流动是粘性流体在两个平面平行壁面之间的剪切流动，它们在没有外部压力梯度的情况下相对于彼此运动。流动的简单公式和几何形状简化了数值算法的实现和它们的比较。
	城市空气质量、化学污染物扩散、气溶胶分布预报等问题增加了大气模式的计算复杂性。一般来说，它们可能需要对不同示踪剂物种浓度的100多个额外的预测方程进行数值求解。类似的计算问题也出现在海洋-生物化学耦合模型中。在这项研究中，我们考虑被动示踪剂的输运作为这些模型的代理，用物质浓度的平流-扩散型方程补充了湍流平面Couette流的DNS模型。这使我们能够评估求解标量传输方程的算法在不同CPU体系结构上的实现效率以及内存优化的作用。
	这篇论文的结构如下。在第一节中，我们介绍了DNS模型的控制方程和数值方法。第2节回顾了用于比较研究的DNS代码的实现方面。第3节和第4节给出了针对特定CPU的数值实验的设置以及代码调优和编译的细节。第5节讨论了性能比较的结果和内存优化的影响，随后是总结和结论。
```

### Performance Evaluation of ParalleX Execution model on Arm-based Platforms

```
Gupta N, Ashiwal R, Brank B, et al. Performance Evaluation of ParalleX Execution model on Arm-based Platforms[C]//2020 IEEE International Conference on Cluster Computing (CLUSTER). IEEE, 2020: 567-575.
```

```
ARM平台上Parallex执行模型的性能评估

	Abstract.
	HPC社区对在CPU生态系统中创建多样性表现出了浓厚的兴趣。基于ARM的处理器的出现为现有的主要由x86处理器主导的HPC生态系统提供了另一种选择。在本文中，我们移植了一个基于Parallex模型的异步多任务运行系统，即High Performance Parallex(HPX)，并在ARM生态系统上用一套基准测试对其进行了测试。我们编写了这些基准测试，重点是向量化和分布式伸缩。我们展示了在各种ARM处理器上的性能结果，并将其与英特尔的x86同类处理器进行了比较。我们表明，所获得的结果与他们的x86兄弟一样好或更好。最后，我们还讨论了目前ARM生态系统的几个缺陷。
	Introduction.
高性能生态系统对从传统的x86架构转向基于ARM的处理器表现出了浓厚的兴趣。名为Fugaku[1]的日本艾级系统基于富士通的A64FX处理器。在欧洲，欧洲处理器倡议(EPI)正在研究一种处理器，该处理器将(除其他外)包括基于ARM的核心，并被定位为高性能计算技术。在美国，桑迪亚国家实验室已经部署了一个基于Marvell的ThunderX2处理器的大规模系统，该处理器基于ARMv8 ISA。这一发展引发了一个问题，即HPC软件生态系统是否准备好利用ARM。这尤其涉及ARM ISA的一个最新扩展，称为可伸缩向量扩展(Scalable Vector Extension，SVE)。与Intel的A VX或A VX512不同，SVE与矢量长度无关，后者的SIMD宽度分别固定为256位和512位。在为SVE编程时，大小会产生一些重要的影响。对于AVX和AVX512(以及类似的SIMD ISA)，定义的数据类型(例如，对于八个双精度向量的m512d)具有在编译时已知的大小。对于SVE，这是先验的，而不是这种情况，因为只有在运行时才知道向量长度。这些硬件复杂性与软件复杂性相匹配。需要操作系统、编译器和库支持来提供支持大规模HPC应用程序的功能环境，并确保它们都可以轻松地移植到这样的新硬件上并有效地利用它。一类这样的应用程序是通过基于任务的编程来利用并行性的应用程序。异步多任务(AMT)运行时系统对基于任务的编程进行建模，并提供消息传递(MPI)等传统编程模型的替代方案。在AMT模型中，程序可以被分解成任务，每个任务都依赖于生成基于数据流的流程的其他任务。在程序执行过程中，这些任务基于输入数据和生成的DAG被任意启动，从而使多个并发任务能够作为计算内核运行。调度器处理负载不平衡。AMT模型的这些特点使其成为未来算法预计具有更高动态行为和低一致性的时代的一种可行的替代方案。本文探讨了一种基于ARM处理器的AMT模型。第二节介绍了ARM处理器移植和评估的相关工作。第三节讨论Parallex执行模型和HPX。第四节涉及理解基准和结果所需的关键概念。第五节介绍了基准和系统设置，第六节讨论了结果。
	Conclusion.
	本文首先概述了在基于ARM处理器的生产型HPC系统上大规模运行的AMTS的性能。我们将HPX和基准测试移植到ARM处理器上的经验大多很简单。在为SVE类型构建时，我们遇到了一些问题。ARM编译器使用__sizless_struct实现SVE，这使得不可能将SVE类型包装到定制容器中，因为它们在编译时没有大小。目前，只有GCC允许命令行标志使用-MSVE向量位传递SVE向量长度。然而，这是以SVE类型的可移植性为代价的。需要进一步的开发来集成定制容器，以便与__sizless_struct一起工作，从而使应用程序开发人员更容易将其应用程序移植到ARM。我们演示了该应用程序既可在节点上扩展，也可分布式扩展。我们发现，在ARM处理器上的性能与他们的x86同类处理器一样好，甚至更好。对于一维模板，除鲲鹏916外，所有处理器都显示出良好的缩放效果。在鲲鹏916的案例中，糟糕的互联网络是罪魁祸首。对于2D模板，我们观察到具有大高速缓存线的处理器显示出固有的高速缓存阻塞好处(没有显式实现)。这导致性能比预期结果提高了约50%。我们还观察到，与自动向量化代码相比，显式向量化可以显著提高ThunderX2和鲲鹏916的性能，这是因为与自动向量化代码相比，显式向量化显著降低了CPU停滞计数。对于A64FX，我们没有观察到通过使用显式矢量化来获得任何明显的性能优势。
```

### Evaluation of the efficiency of an ARM-based beowulf cluster versus traditional desktop computing for high performance computing

```
Addiego N. Evaluation of the efficiency of an ARM-based beowulf cluster versus traditional desktop computing for high performance computing[J]. 2017.
```

```
基于ARM的Beowulf集群的效率评估基于ARM的Beowulf集群与传统桌面计算在高性能计算方面的效率比较

	Abstract.
	在科学计算领域，关注结果驱动的增长变得越来越重要(Kamil、Shalf和Storhmaier)。这样做使研究人员能够继续建立迅速扩大的科学发现领域。然而，随着增长而来的是实现这些结果所消耗的资源量的成本。大型超级计算机的耗电量大约是传统美国家庭的1.4万倍(美国能源信息管理局)。与此同时，公众消费者一直在推动移动行业及其背后的研究。对一次充电可以持续一整天的移动设备的需求越来越快，这推动了ARM开发的高级精简指令集处理器的开发。这些处理器构建为高效执行，同时仍保持执行必要计算的能力。这项研究着眼于将这两个并行领域结合起来，并分析与传统台式计算机相比，多个ARM处理器的整体效率和能耗。结果显示，与桌面上最慢的测试相比，ARM处理器的效率大约低了两个数量级。有几个变量在这些结果中发挥了重要作用，包括对网络速度和带宽的限制、空闲能源消耗以及各个电源调节器。

	Introduction.
	多年来，随着超级计算机用于计算的问题越来越多，对超级计算机的需求也显著增加。随之而来的问题是对结果的关注，而不是对资源消耗的关注。中国广州的天河二号超级计算机耗电量为17808000W，每小时耗电近3000美元(Meuer、Strohmaier和Donarra)。相比之下，一个传统的60W灯泡必须连续工作34年，才能相当于天河2号在一小时内消耗的电量。如果不关注提高我们在社会中使用的计算过程的可持续性，目前超级计算机的消费趋势将不再经济或环境可行。该项目旨在研究基于ARM的集群与传统台式机在用于大型计算时在总体能源和功率消耗、总体效率以及完成计算所需的总时间方面的比较。
	Supercomputers.
	超级计算机的必要性最初是在某些描述物理现象的方程式被开发出来的时候出现的，这些物理现象如果没有计算机的帮助是无法解决的。这些方程式被圣地亚哥超级计算机中心(见图1)视为大挑战方程式，是最初推动超级计算机(圣地亚哥超级计算机中心)必要性的原因。这些方程中的大多数不能用符号数学来求解，而必须用数值来求解。

	Computational Fluid Dynamics.
	在这些方程中，有一个与本项目特别相关：纳维-斯托克斯方程(见方程1)。纳维尔-斯托克斯方程是一个偏微分方程式，它代表了流体在空间中的运动，以及它们与运动中的作用力之间的关系。本质上，纳维-斯托克斯方程代表了流体应用中的牛顿第二运动定律。主要的问题是，这个方程没有传统的数学解，因此必须使用实验结果来更好地理解方程，或者使用创造性的方法来近似单个有问题的项。这些创造性的解决方案就是所谓的数值逼近。
	
	Numerical Approximations.
	数值逼近被用来逼近Navier-Stokes方程内部的偏微分项。在求方程的解时，这些项是最难解释的。有两种不同的方法来逼近单个偏导数项。第一种方法涉及关于时间的偏微分项。求这些导数最常用的方法是逼近所讨论函数的斜率。Runge-Kutta四阶数值逼近法是一种利用感兴趣变量前后的多个值来估计斜率瞬时值的方法。这种近似是通过将偏微分方程转化为一组具有固定初始条件的常微分方程组来实现的，这些初始条件更容易求解。近似的阶数越高，微分方程的精度和表示形式就越高。然而，随着精度的提高，计算斜率需要的值更多，计算时间也会增加。另一种方法用来求出关于方向的偏微分项。傅里叶变换允许用物理量表示的函数，并将它们转换成由波形表示的量。这些变换允许用简单的线性数学计算复杂的偏微关系。通过将快速正向傅立叶变换(FFT)的结果乘以虚单位和特定波数，可以计算出变量相对于一个方向的偏导数。然后，可以通过反快速正向傅立叶变换(IFFT)发送该结果，以获得相对于波数中使用的方向的偏微分项(参见图2)。重要的是要注意，就所消耗的资源量而言，傅立叶方法计算这些项的成本很高。虽然可以使用其他方法计算它们，但结果远不如傅立叶方法准确。
	
	Parallel Computing.
	在计算机界，有两种主要的方法来处理数据。在大多数典型的软件应用程序中，所有必要的命令都会一个接一个地执行，其中下一个命令直到前一个命令完成后才能执行。这种一次只允许处理一条指令的方法称为串行计算。另一种方法称为并行计算。并行计算涉及获取相同的命令，并将它们分解为更小的组件，在这些组件中，不同的部分可以同时执行。并行计算是指进行一次串行计算，并将其划分为几个较小的串行问题，这些问题可以串联执行。这种方法允许同时计算彼此独立的计算，从而显著减少了所需的总体计算时间。

	ARM Processors.
	随着移动电话和其他手持设备的兴起，降低处理器的整体功耗变得越来越重要。因此，Acorn Computer Group研发了第一个ARM处理器，命名为Acorn Reduced Instruction Set Machine。随着个人数字助理(PDA)的出现，精简指令集机(RISC)在20世纪90年代初进行了改进。这一改变旨在减少处理器的时钟周期未使用时发生的耗电量。这使得电池的续航时间大大延长，这在手持设备中是必要的。在苹果公司的资金援助下，橡子计算机集团成为一家新的半导体公司，旨在创建一种新的微处理器标准。基于ARM的芯片一直在不断发展，其板条箱速度更快，仍然优先考虑降低总体功耗(Levy)。
	
	Conclusions.
	研究结果表明，目前基于ARM的处理器用于低功耗高性能集群的可行性是有限的。使用Beowulf集群带来的限制限制了使用高级网络设备实现集群最大理论计算能力的总体能力。这个限制是集群的成本将显著增加，这违背了COTS Beowulf集群的定义。此外，与运行状态相比，集群闲置使用的电量表明，处理器管理关键计算任务的方式效率很低。
展望未来，有几个关键领域可以解决，以改进集群。第一个领域是Odroid董事会本身。集群的大部分由基于XU3的主板组成，这些主板于2014年发布(HardKernel)。较新的基于XU4的主板改进了硬件，包括更新的USB3.0以太网控制器和本地千兆位以太网连接。这两个更新将显著提高通信的可用速度，从而在不增加耗电量的情况下极大地提高集群的整体性能。另一个可以研究的变量是各个电力监管机构。目前，每个计算板都有自己的调节器，为电路板提供5伏电压。这些监管机构中的每一个都与生俱来地失去了一些权力。总而言之，所有单个监管机构的损失可能会对柏林墙的整体读数产生重大影响。为了研究这一点的影响，一个带有一个调节器的母线电力系统将显示单个调节器损失了多少电力。
```

### Identifying representative regions of parallel HPC applications: a cross-architectural evaluation

```
Ferreron A, Jagtap R, Rusitoru R. Identifying representative regions of parallel HPC applications: a cross-architectural evaluation[C]//2016 IEEE International Symposium on Workload Characterization (IISWC). IEEE, 2016: 1-2.
```

```
确定并行HPC应用程序的代表性区域：跨体系结构评估

	Abstract.
	随着高性能计算(HPC)系统的规模越来越大，仿真的时间和资源成本也随之增加。选择并行应用程序的代表性部分以降低模拟成本的工具非常普遍，例如BarrierPoint通过分析基本块和重用距离等抽象特征来实现这一点。然而，HPC的新架构将只有一组有限的工具可用。在这项工作中，我们在Intel和ARM上对用于识别基于抽象特征选择的并行HPC代理应用程序的代表性感兴趣区域的方法进行了跨体系结构评估。我们观察到，我们可以通过运行较短的代表性部分来预测完整应用程序执行的性能。这使得总的模拟时间减少了2.5倍到166倍，同时将周期和指令的误差保持在3.3%以下。
 
	Introduction.
	高性能计算(HPC)通过实现复杂问题的空间探索，改变了我们进行科学研究的方式。下一个HPC挑战是实现Exaflop：在20兆瓦的功率预算中实现每秒10^18次浮点运算(FLOPS)。在功率成为主要限制的情况下，ARM架构在高性能计算中变得越来越重要。要达到艾级标准，就需要在技术、架构、软件和可编程性方面进行创新。这种创新依赖于模拟未来系统的能力。由于系统复杂性的增加，模拟时间也增加了，从而使系统设计人员和研究人员无法运行完整的高性能计算应用程序。这个问题在诸如Gem5这样的全系统模拟器中更加明显，它可以对不同的微体系结构进行更详细的建模。鉴于上述问题，重要的是获得对整个应用程序行为建模的代表性部分，将模拟仅限于核心部分。这允许在不影响结果代表性的情况下减少总执行时间。在这种情况下，抽样方法，如BarrierPoint，非常流行。BarrierPoint方法使用障碍作为自然同步点来界定应用程序阶段，称为障碍点。该方法分析高层抽象特征，例如控制流(即，基本块)和存储模式(即，重用距离)，以确定代表性区域。这些具有代表性的障碍点可以并行模拟，从而实现高模拟速度。在本文中，我们评估前面提到的抽象特征是否适合于跨不同的体系结构特征(如向量能力和指令集体系结构(ISA))提取高性能计算应用程序的代表性部分。我们构建在BarrierPoint方法的基础上，并观察到我们的工具扩展可以比最初显示的更广泛地应用，即跨x86_64和ARMv8。
	
	Conclusion.
	我们已经看到，BarrierPoint方法可以成功地应用于一组跨越两种不同架构(x86 64和ARMv8)的HPC代理应用程序，并跨越架构功能的变化，例如矢量功能。这很有价值，因为它允许在一个架构上本地分析应用程序，然后收集各种架构上的结果。结果表明，对于x86 64和ARMv8体系结构，可以估计整个应用程序的性能(以周期和指令为单位)，误差小于3.3%。当考虑代码的矢量化版本时，可以得到类似的结果。我们在仅运行总工作负载的0.6%、最高运行38.8%的情况下实现了这一点。未来，我们计划对这项工作进行扩展，以便将其适用于更多的工作负载。我们想要探索的一些机会是调整障碍点的大小，并将其推广到非OpenMP应用程序上。
```



## 论文中使用：

### [1] 高性能计算的发展

```
臧大伟, 曹政, 孙凝晖. 高性能计算的发展[J]. 科技导报, 2016, 34(14): 22-28.
```

```
继理论科学和实验科学之后，高性能计算成为人类科学研究的第三大范式。作为科技创新的重要手段，高性能计算广泛应用于核爆模拟、天气预报、工程计算等众多领域，是当代科技竞争的战略制高点，集中体现一个国家的综合实力。本文介绍高性能计算发展的历史和现状，分析当前高性能计算所面临的问题和挑战，探讨高性能计算未来的发展方向。
```

### [2] 话说超级计算

```
李新亮. 话说超级计算[J]. 力学与实践,2022,44(01):243-245.
```

```
介绍了超级计算(大规模并行计算)的基本概念，回顾了近20年来我国超级计算的发展历程。介绍了异构性计算的基本概念和并行计算的基本编程方法。
```

### [3] Current prospects towards energy-efficient top HPC systems

```
Filiposka S, Mishev A, Juiz C. Current prospects towards energy-efficient top HPC systems[J]. Computer Science and Information Systems, 2016, 13(1): 151-171.
```

```
高能效TOP HPC系统的现状与展望

	Abstract. 自从绿色高性能计算机倡议开始以来，顶级超级计算机设计者的地平线上就出现了一个新的设计限制。今天的顶级HPC不仅必须夸耀其艾级性能，还必须考虑以尽可能低的功耗达到新的Exaflop边界。本文的目的是从性能和功耗两个角度介绍顶级超级计算机的现状。使用来自Top和Green HPC排行榜的当前和可用的历史信息，我们确定了最有希望的设计选项，以及当它们组合在一起时如何执行。目前的结果揭示了应成为未来研究重点的主要挑战。
	高性能计算日益成为一种主流的计算模式，不仅适用于科学计算，而且适用于许多其他应用。对于制造商和用户来说，最大限度地发挥其性能(如每秒浮点运算(FLOPS)的数量)是当务之急。每年两次，在国际超级计算大会上，都会编制TOP 500，其中包含了根据高性能Linpack基准(HPL)衡量的最强大的HPC系统。第一份榜单是在1993年发布的，从那时起，世界上最强大的计算系统的峰值性能能力已经增加了5个数量级。但是，增加更高的性能是以高昂的成本为代价的：需要更多的电力来为这些系统供电。目前，TOP 500上最耗电的系统需要近20兆瓦的能源，相当于一家小型火力发电厂的产量。对这些超级计算机施加电力限制的兴趣越来越大，导致了另一个竞争名单的建立，Green 500。该列表使用了相同的基准测试工具，但排名值是性能与所用功率的比率，以每瓦的MFLOPS表示，而不是只关注FLOPS。
	通过回顾列表中的历史变化并分析不同系统特征中的变化，我们可以跟踪导致今天的Petaflop顶级超级计算机的技术发展和设计修改的历史。这两个列表展示了HPC系统开发中的优势和劣势的不同故事。因此，在第一眼看到排名靠前的数据后，我们发现自己想知道，随着更多强大的新计算机进入榜单，顶级超级计算机的排名会随着时间的推移而发生变化。作为这种缓慢退出场景的一个例子，图1中给出了两个列表的动态，通过6年的时间跟踪单个示例系统。从我们观察到的例子中，我们可以得出结论，在最初的几年里，最高性能的超级计算机在Top500榜单上的排名正在慢慢下降，随着年龄的增长，它们的排名下降变得更加明显。与同一系统的绿色性能相比，我们观察到绿色500榜单上的绿色性能几乎稳步下降，这导致了名单上的新来者更经常表现出更高的绿色性能，从而支持了对未来系统的绿色高性能控制设计的认识增加的说法。通过比较过去和现在的这两份清单，可以注意到高性能混凝土发展中的许多重要里程碑。此外，许多技术改进，无论是性能还是功率，都在这些清单上留下了重要的印记。更深入地了解这些清单、它们的趋势和相关性，可以帮助指导研究和行业在未来几年走向亿级超级计算机。对这些系统的详细检查和交叉比较可以挖掘出大量有关节能体系结构的信息，这些体系结构应该在未来得到利用和开发，以进一步改进绿色高性能计算计划。本文的主要目标是通过分析当今领先的计算机系统所展示的技术来推断高性能计算机系统的效率和功耗的未来。目标是洞察当前最佳架构的性能与功率趋势，并确定处理器、互连、系统系列等方面的方向，以显示稳定状态的改进，并为未来节能高效的HPC系统铺平道路。
	自1993年建立以来，500强榜单已经成为高性能计算行业、研究和应用领域的主要参与者衡量其进展的舞台。使用的唯一指标是最大性能(Rmax)，以Flop为单位。这场竞争激烈的开发竞赛导致了对电力需求巨大的系统的构建，这些系统需要维持或提高其性能。认识到设计耗能高的高性能计算机系统的不可持续性，近年来，致力于高能效的高性能计算机设计的努力正在上升。这一绿色的HPC倡议导致了一项新名单的提议，即绿色500。这项提议的主要思想是建立额外的、节能的指标来对最强大的HPC系统进行排名。自2007年以来，与TOP500榜单平行的是《绿色500强》。随着时间的推移，这两份清单都成为高性能计算系统开发的丰富历史数据来源，可以用来更好地解释当今的技术和预测未来的趋势。因此，Green500名单被用作对未来超级计算机的电力消耗进行第一次预测的基础。然而，目前的结论大多是基于动力或绩效与绿色效率之间的相互依赖关系的分析，这意味着预测是基于分别分析绿色指标和用于计算绿色指标的两个变量之一之间已经存在的内在关系的函数。因此，结果主要是由于指标之间存在的自然相关性，正如我们在本文中进一步介绍的那样。类似的方法也可以在中看到，其中作者构建了略有不同的复合指标，这也是基于性能和效率，而在实验中，对Green500列表中使用的功率测量方法进行了验证，使可以使用列表中的信息进行的分析具有现实的权重。在考虑大多数HPC系统的构建块时，尝试分析系统组件的能效时，还可以考虑另一个不同的基准。基于标准SPEC基准的SPECpower_ssj2008将自己确立为标准的服务器能耗基准。它使用特殊的方法来测量基准测试过程中的功耗。基准测试结果是在使用典型的服务器端Java应用程序处理业务事务时，不同负载级别的功耗与所获得的性能分数相关。所有不同负载水平的结果被用来计算总体功率性能指标。中提供了对2010年SPECpower_ssj2008榜单的深入分析。不幸的是，SPECpower结果数据库没有定期更新，这使得该数据集不完整、过时且难以使用。此外，一些最重要的供应商最近似乎已经停止发布他们的SPECpower结果。由于这些原因，顶级列表似乎仍然是能够提供顶级超级计算机体系结构、性能和特征的当前状况的唯一信息来源。高性能计算系统的整体效率取决于它的许多要素。为了能够更深入地反映高性能计算系统的不同组件对整体效率的贡献，已经做出了努力来改进FLOPS/WAT度量。其中一项建议是在2009年引入的绿色指数。这种方法背后的想法是拥有一个单一的数值，该数值将捕获整个系统的能效。
	从2013年开始，Green500增加了其他数据，如：系统系列、互连等。尽管这些数据已经出现在TOP500列表中，但由于信息不完整和不同系统之间的模棱两可，两个列表的匹配很困难，使得整体性能/功率分析繁琐且容易出错。在这些最新增加的基础上，给出了各种设计方案对效率的影响，以及一些初步的历史趋势、最有希望的设计和应该指导未来研究工作的主要挑战。在这篇文章中，我们更新和扩展了开始的工作，以阐明最新的进展以及描述顶级HPC系统的不同参数之间的相互依赖关系。
	Conclusion. 通过对高性能混凝土系统绿色效率的分析，得出了高性能混凝土建筑设计中关键决策的几个重要结论，为实现最低能耗的最佳性能铺平了道路。为了确保未来高性能混凝土主流技术的绿色性能，设计人员应专注于构建将缩小现有理论性能与已实现性能之间差距的异质系统。我们的分布分析证实了这种方法的可行性，表明自绿色倡议开始以来，与电力消耗的增加相比，性能的增长率更高。由于功耗对绿色排名的影响很大，而它本身又主要是由于“纯”核的数量，所以未来绿色高性能计算系统的计算能力应该主要使用加速器核(90%以上)来实现，这些加速器核只会积极地诱导高Rmax。然而，为了确保加速器核心将提供所追求的性能，必须仔细选择系统的其余部件。各种HPC设计选项的交叉比较指向Haswell低功耗高性能处理器系列，在精心设计的系统系列机箱中结合InfiniBand互连，该系统系列机箱采用基于液体的单个元件冷却以及热平衡调度器。然而，仍然有其他开放的问题必须解决，主要问题是简化应用程序开发和高效地移植到异类环境。
```

### [4] A methodology for full-system power modeling in heterogeneous data centers

```
Canuto M, Bosch R, Macias M, et al. A methodology for full-system power modeling in heterogeneous data centers[C]//Proceedings of the 9th International Conference on Utility and Cloud Computing. 2016: 20-29.
```

```
当前数据中心对能源意识的需求鼓励使用电力建模来估计其电力消耗。然而，现有模型存在明显的局限性，这使得它们依赖于应用程序、依赖于平台、不准确或计算复杂。在本文中，我们提出了一种与平台和应用无关的方法，用于在异构数据中心中进行全系统功耗建模，以克服这些限制。它通过系统地选择一组最小的资源使用情况指标并提取它们之间的复杂关系来获取系统中所有资源对能源消耗的影响，从而为具有不同资源使用和能源消耗模式的不同类型的应用程序提供高精度的每个平台的单一模型。我们通过为具有非常不同的功耗配置文件的不同平台生成电源模型来演示我们的方法。我们对真实云应用的验证实验表明，这种模型具有很高的精度(平均估计误差约为5%)。

在本文中，我们提出了一种与平台和应用无关的方法，用于异类数据中心的全系统功耗建模，方法是在运行特定培训工作负载时收集功耗和资源使用情况测量数据，并通过机器学习对其进行拟合。我们的方法克服了前人工作的局限性。它通过系统地选择最小的一组资源使用指标并提取它们之间的复杂关系来得出每个平台的单一模型，这些关系反映了所有资源对能源消耗的影响。我们已经通过为具有非常不同的功耗配置文件的不同平台生成功率模型来演示我们的方法，从基于Intel Xeon和AMD皓龙的高性能服务器架构到基于Intel Atom和ARM Cortex-A的低功耗架构。我们对以CloudSuite和NAS基准为代表的不同资源使用和能耗模式的真实云应用程序进行的实验表明，此类模型提供了高精度(平均估计误差的5%左右)，并且功耗估计与执行时间图中的实际功率测量结果密切相关。作为我们未来工作的一部分，我们将增强我们的方法，以对单个虚拟机和容器的功耗进行建模。我们还计划使用电源模型来驱动节能调度策略，以选择最方便的主机来执行每个应用程序。
```

### [5]Preliminary Investigation of Mobile System Features Potentially Relevant to HPC

```
Pruitt D D, Freudenthal E A. Preliminary investigation of mobile system features potentially relevant to HPC[C]//2016 4th International Workshop on Energy Efficient Supercomputing (E2SC). IEEE, 2016: 54-60.
```

```
能源消耗在科学计算中的重要性日益增加，促使人们对开发高效节能的高性能系统产生了兴趣。移动计算的能量限制推动了能够支持各种计算密集型用户界面和应用的低功耗计算系统的设计和发展。其他人观察到移动设备也在进化，以提供高性能。他们的工作主要检验了计算密集型科学程序的性能和效率，这些程序要么在移动系统上执行，要么在非移动(有时是HPC)系统中嫁接的移动CPU的混合系统上执行。这份报告描述了对五个高性能和移动系统上的单个科学代码的性能和能源消耗的调查，目的是确定各种建筑特征的性能和能效影响。这项初步研究的结果表明，与系统体系结构的其他特定方面相比，ISA在实现高性能和高效率方面没有那么重要。这项研究中采用的策略可以扩展到具有各种存储器访问、计算和通信特性的其他科学应用程序。

ISA与实现特性的相关性：如所示，观察到的性能和能效差异主要是由于浮点子系统的实现特性、内存层次结构、时钟频率和流水线深度，而不是ISA。在COMD的情况下，性能差异似乎主要归因于浮点吞吐量的差异。这表明，与其他实现特征相比，指令集族的总体特征(例如，RISC/CISC，甚至字长)与能量消耗和性能的相关性可能较小。对HPC ARM系统的担忧：HPC ARM的浅缓存层次结构因来自COMD的缓存未命中而变得足够拥挤，从而在高度并行的情况下显著降低了吞吐量。COMD具有很高的缓存命中率。L1缓存命中率较低的应用程序可能会在L2缓存上产生更多拥塞，因此被限制为甚至更低的并行效率。可能具有高性能和在当前移动平台上的应用程序的特征：我们惊讶地发现，尽管移动系统结合了低电压信令，但我们检查的所有系统上的DRAM通信信道都具有类似的性能特征。与HPC系统合并四个信道相比，移动系统合并了其中的一个或两个。由于Comd提供的内存和浮点负载远远低于所有移动平台的吞吐量，因此，与HPC Intel上的吞吐量相比，产生更高内存和浮点吞吐量的应用程序很可能在移动平台上执行时只会增加速度减慢。其产生浮点流量的速率低于COMD的应用程序在移动平台上的执行吞吐量可能与英特尔HPC相似。与HPC相关的移动系统的特征：空闲功率是本研究中考察的HPC和移动系统之间的主要区别。我们观察到，移动系统结合了具有节能功能的网络、I/O和存储器接口，例如低电压信令和各种形式的低功率待机模式。这些节能功能通常不会出现在HPC系统上。这一设计决策在两个方面对能源效率产生了不利影响。如果I/O接口在空闲时占用其有效功率的很大一部分，则会增加整个系统的空闲功率需求。如结果部分所述，竞速到空闲策略可能会产生最高的效率，其副作用是降低整个系统的能效。此外，如果系统在功率上限下运行，将功率分配给未充分利用的设备将减少可用于支持有用计算的能源量。因此，如果未来的HPC系统结合了移动系统中常见的策略，从而降低了整个计算系统中未充分利用的组件的能量消耗，那么未来HPC系统的能源效率可能会显著提高。

ISA:指令集体系结构(Instruction Set Architecture, ISA)，简称体系结构或系统结构(architecture),它是软件和硬件之间接口的一个完整定义。ISA定义了一台计算机可以执行的所有指令的集合，每条指令规定了计算机执行什么操作，所处理的操作数存放的地址空间以及操作数类型。
```

### [6]A survey of high-performance computing scaling challenges

```
Geist A, Reed D A. A survey of high-performance computing scaling challenges[J]. The International Journal of High Performance Computing Applications, 2017, 31(1): 104-113.
```

```
20年前，当商品集群首次出现时，它们给高性能计算带来了革命性的变化。随着规模和复杂性的增加，在可靠性和系统复原力、能效和优化以及软件复杂性方面出现了新的挑战，这表明有必要重新评估目前的办法。本文回顾了最先进的技术，并反思了在构建跨千万亿级计算系统时可能面临的一些挑战，使用从操作经验和社区辩论中获得的见解和观点。

先进计算的世界与中等规模的商品集群还是一个新概念的时候有很大不同。我们在使用商品组件进行大规模系统设计和运行方面学到了很多经验。然而，这些同样的成功也给跨百万亿的政权带来了令人望而生畏的新挑战。随着跨千万亿级系统的节点数量增长到数万个，而且拟议的亿级系统可能包含数十万个节点和十亿路并行，完全可靠的硬件操作的假设变得不那么可信。虽然单个组件(即处理器、磁盘、内存、电源、风扇和网络)的MTBF很高，但大量的总组件数量意味着组件故障现在和将来都是经常关注的问题。复原力的系统设计、部件验证的制造和测试以及算法和软件复原力都是规模化操作复原力的基本要素。不断增加的系统规模带来了围绕能源可用性和成本的互补挑战，预计系统将消耗数十兆瓦的电力。在这种规模下，能源可获得性和成本都成为重要的设计和运营约束，这体现在作业调度策略和资源分配上。此外，研究人员资源分配和使用的成本不仅仅是抽象的。它们是真正的经济选择，对HPC系统运营商和研究资助机构具有影响。在能源效率挑战的推动下，跨百兆时代出现了两种不同的建筑设计。一种是以包含多核CPU和加速器的少量异类节点为代表，另一种是以数量较多的同构节点为代表。为了使未来的亿级系统可用，我们似乎必须开发新的设计方法和运行原则，以体现大型系统的三个重要现实：(A)频繁的硬件部件故障是正常运行的一部分；(B)必须与性能和弹性一样仔细地管理能源消耗和电力成本；以及(C)必须管理软件的复杂性，以降低软件开发成本。在每种情况下，都可以从商业云计算中学到关于组件调整和优化、能源管理和效率以及编程效率的潜在经验教训。许多架构和软件问题在这两个领域都是共同的。
```

### [7] Performance of Devito on HPC-Optimised ARM Processors-big

```
Senger H, de Souza J F, Gomi E S, et al. Performance of Devito on HPC-Optimised ARM Processors[J]. arXiv preprint arXiv:1908.03653, 2019.
```

```
我们在ARM ThunderX2处理器上评估了Devito的性能，这是一种用于有限差分的域特定语言(DSL)。使用两个常见的地震计算内核进行的实验表明，与其他Intel Xeon处理器相比，ARM处理器可以提供与之相当的性能。

结果表明，基于ARM的处理器能够提供与最先进的Intel Xeon处理器类似的性能来执行地震反问题。此外，Devito被证明能够为ARM处理器生成高效的高性能代码。所有模型都成功编译和运行，无需特定于体系结构的代码调优即可实现高性能。
```

### [8] Is Arm software ecosystem ready for HPC?

```
Banchelli Gracia F F, Ruiz D, Hao Xu Lin Y, et al. Is Arm software ecosystem ready for HPC?[C]//SC17: International Conference for High Performance Computing, Networking, Storage and Analysis. 2017.
```

```
近年来，HPC社区对ARM架构的兴趣与日俱增，研究项目主要针对基于ARM的集群的安装。最先进的研究项目的例子有欧洲的万宝龙、日本的后K和英国的GW4/EPSRC。通常主要关注硬件平台，随着硬件通过借用移动市场(例如Big.LITTLE)的解决方案和ARMv8-A可伸缩向量扩展(SVE)技术等附加技术向HPC工作负载发展，ARM HPC社区正在增长。然而，成熟的软件生态系统的可用性和运行大型且复杂的HPC应用程序的可能性在新技术的整合过程中发挥着关键作用，特别是在像HPC这样保守的市场。因此，在这张海报中，我们对ARM系统软件生态系统进行了初步评估，仅限于ARM HPC编译器和ARM性能库，并移植和测试了三个相当复杂的HPC代码套件：QuantumESPRESSO、WRF和FENICS。这些代码的选择并不完全是随机的：事实上，它们已经在ISC的最后两届学生集群竞赛中被提出为HPC挑战赛，所有作者都参与了基于ARM的集群的运营，并获得了球迷最喜欢的奖项。

关于编译器，在串行环境中，我们注意到ARM HPC编译器在涉及矩阵-矩阵运算的基准测试中的性能显著提高，平均而言，我们重现了已经研究过的行为。在并行环境中，我们注意到在使用ARM HPC编译器时，在更多核心数和细粒度并行的情况下性能更好。这似乎与在ARM HPC编译器的OpenMP运行时创建/销毁线程的开销较低有关。在存在更粗粒度的并行性的情况下，线程创建/销毁的开销不那么显著，两个编译器有类似的趋势，略有优势∼20%，有利于GCC。在数学库方面，在DGEMM微基准测试中使用ARM性能库2.2.0获得的性能与其他优化库在小矩阵尺寸下提供的性能相当。当矩阵大小大于1500×1500个元素时，可以显著提高性能。ARM性能库还可能过早实现与FFT相关的函数，这些函数可以在调用FFTW库函数的时刻得到补偿。大型生产HPC代码的评估是完美的，使我们能够构建和执行两个模块化套件WRF和FENICS，支持所有可用的并行性，没有重大障碍。总的来说，ARM软件生态系统已经被证明足够成熟，即使在学生集群竞赛这样的教育项目中，也可以在基于ARM的集群上运行而不受主要限制。在性能方面，结果与其他主流可比软件(如GCC，ATLAS，BLAS，OpenBLAS)一致，但有两个例外：i)ARM工具允许在矩阵-矩阵运算中达到显著更好的性能，而ii)FFT部分应进一步优化工作。
```

### [9] Comparing Allinea"s and Intel"s Performance Tools for HPC

```
Luecke G R, Groth B M, Weeks N T, et al. Comparing Allinea's and Intel's performance tools for HPC[C]//Proceedings of the 25th High Performance Computing Symposium. 2017: 1-12.
```

```
要高效地使用高性能计算机，优化应用程序以获得高性能至关重要。要实现这一点，HPC开发人员必须利用性能工具在大型、复杂的科学应用程序中发现并纠正性能问题。Allinea和英特尔提供供应商支持的性能工具，这些工具会定期更新，以获取最新硬件上的重要性能指标。在本文中，作者对Allinea的MAP性能工具和Intel的性能工具进行了评估和比较，以帮助进行应用程序优化。作者发现，Allinea的地图提供了使用直观、易于使用的用户界面诊断和修复性能问题所需的有用性能指标。英特尔的性能工具以更复杂的用户界面为代价，提供了更详细和可定制的应用程序性能视图。本文提供的比较将帮助HPC开发人员确定哪种性能工具最适合他们。

使用混合MPI+OpenMP版本的EPSNP，作者评估了Allinea和Intel Performance Tools的功能和易用性。就我们的功能标准而言，得分最高的工具是MAP，因为它包含应用程序优化所需的功能。MAP有一个用于检测MPI负载不平衡的Yes∗，因为Metric View可以暗示负载不平衡，但不像ITAC中那样提供直接检测。英特尔跟踪分析器和采集器(ITAC)在这一类别中得分较低，因为它缺乏详细的源代码支持、内存指标和I/O指标。然而，作者认为ITAC的MPI功能，特别是事件时间线图表和负载平衡图表特别有用。

要使用英特尔的性能工具评估MPI应用程序的性能，必须使用两个工具：用于MPI通信的ITAC和用于确定源代码中的瓶颈的VTune或PFLET。因此，Allinea map是一个工具，它同时提供MPI通信的性能数据和源代码级的评测信息。作者认为这是MAP相对于ITAC或VTune的优势。此外，作者认为MAP的用户界面比ITAC或VTune的不同界面更直观。Allinea还有一个高级的、易于使用的性能工具，称为性能报告。此工具不需要重新编译。综合起来，ITAC和VTune摘要页提供的信息与性能报告类似，但这需要应用程序运行两次(每个工具运行一次)。此外，性能报告会提供性能改进建议，而英特尔的工具则不会。作者认为这些建议是有价值的，并希望其他工具也能实现类似的分析，以帮助程序优化。但是，要在使用性能报告后发现性能问题，可能需要使用其他需要编译源代码的工具进行额外的运行。图形用户界面的响应性是另一个重要的考虑因素。与X11转发相比，MAP的远程客户端显著提高了可用性，因为它减少了通信延迟。它还减少了集群登录节点上的负载，因为图像渲染将移动到用户的工作站。在表3这张表中，我们给出了两个等级：满意(S)和需要改进(NI)。在这里，性能报告和英特尔性能函数或循环执行时间(PFLET)不使用图形用户界面，因此它们被归类为N/A。
```

### [10] 华为鲲鹏920: 一颗勇敢的“芯”

```
苏月. 华为鲲鹏 920: 一颗勇敢的 “芯”[J]. 计算机与网络, 2019, 21.
```

```

```

### [11] Benchmarking the first generation of production quality Arm-based supercomputers

```
McIntosh‐Smith S, Price J, Poenaru A, et al. Benchmarking the first generation of production quality Arm‐based supercomputers[J]. Concurrency and Computation: Practice and Experience, 2020, 32(20): e5569.
```

```
在本文中，我们展示了两台生产质量超级计算机的扩展结果，它们使用第一代基于 Arm 的 CPU，这些 CPU 已针对科学工作负载进行了优化。两种系统均使用 Marvell ThunderX2 CPU，可提供高核心数和一流的内存带宽。第一个系统是 Isambard，它是由 GW4 联盟和英国气象局运营的 Cray XC50“侦察兵”系统，作为二级国家高性能计算服务。第二个系统是三个基于 Arm 的 HPE Apollo 70 系统之一，作为 Catalyst UK 项目的一部分，在布里斯托大学运行。我们将这两个系统的扩展结果与基于 Intel Skylake 和 Broadwell CPU 的三个 Cray XC50 系统进行比较。我们专注于对英国国家 HPC 服务 ARCHER 和我们的项目合作伙伴很重要的一系列应用程序和迷你应用程序。我们还比较了基于 Arm 的 HPC 系统上可用的最先进工具链的性能和成熟度。

本文提供的结果表明，使用基于 Arm 的处理器构建的超级计算机现在提供的生产性能与现有处理器供应商的最先进产品具有竞争力。我们发现，即使在具有更高峰值浮点性能的基于 x86 的 CPU 可以在低节点数下击败 ThunderX2 的情况下，在适合实际科学运行的实际规模下，ThunderX2 通常也会变得更具竞争力，因为其更大的内存带宽有利于通信表现。我们还看到，大多数代码在 x86 和 ThunderX2 之间以及在具有不同互连技术的两个 ThunderX2 系统之间的缩放比例相似。随着未来基于 Arm 的处理器将通过引入 Arm 可扩展矢量扩展等新技术来提高浮点性能和缓存带宽，这些供应商的 CPU 产品将变得更加引人注目。我们的大多数基准测试都开箱即用地编译和运行，并且不需要针对特定架构的代码调整来实现高性能。这代表了 Arm 高性能计算生态系统成熟的一个重要里程碑，这些处理器现在可以被视为未来生产采购的可行竞争者。总体而言，这些结果表明，针对 HPC 进行了优化的基于 Arm 的服务器 CPU 现在是生产系统的真正选择，可提供与同类最佳 CPU 相媲美的大规模性能，同时可能提供具有吸引力的性价比优势。随着多家系统供应商现在提供使用这些 CPU 作为其标准产品组合的一部分的解决方案，基于 Arm 的处理器有望成为科学计算领域未来的一部分。
```

### [12]ThunderX2 Performance and Energy-Efficiency for  HPC Workloads

```
Calore E, Gabbana A, Schifano S F, et al. ThunderX2 performance and energy-efficiency for HPC workloads[J]. Computation, 2020, 8(1): 20.
```

```
在过去几年中，由于环境、技术和经济原因，HPC 系统的能源效率变得越来越重要。几个项目已经调查了不同处理器和加速器的使用，以寻求能够为数据中心和 HPC 安装实现高能效水平的构建系统。在此背景下，Arm CPU 架构因其在低功耗和低能耗应用中的广泛应用而备受关注，而服务器级处理器则是最近才出现在市场上。在这项研究中，我们以 Marvell ThunderX2 为目标，这是一款最新的基于 Arm 的处理器，旨在满足高性能计算应用的要求。我们的兴趣主要集中在大型 HPC 安装环境中的评估，因此我们使用 ERT 基准和两个 HPC 生产就绪应用程序评估了计算性能和能源效率。最后，我们将结果与大型并行系统中常用的其他处理器进行了比较，并突出了可受益于 ThunderX2 架构的应用程序在计算性能和能源效率方面的特点。为实现这一目标，我们还描述了如何针对 ThunderX2 修改和优化 ERT，以及如何在此处理器上运行应用程序时监控功耗。

在这项研究中，我们分析了 Marwell 针对服务器市场发布的基于 Arm 的 ThunderX2 处理器的性能。我们考虑了计算和能源性能，并评估了哪些类别的 HPC 应用程序更适合充分利用该处理器。为此，我们最初修改了 ERT 基准以针对 Arm 架构进行优化。这是必需的，因为原始代码针对其他指令集（例如 x86）进行了优化，但不适用于 Arm，并且无法充分利用与实现大部分浮点相关的 TX2 融合乘加指令表现。使用 Arm 优化版本的 ERT 基准测试，我们绘制了一个经验 Roofline 图，以比较内存带宽和计算吞吐量与 HPC 系统中常用的两个英特尔处理器。 Roofline plot 显示，TX2 的机器平衡值最低，内存带宽最高，计算性能低于 Skylake，但与 Haswell 相似。这些结果表明 TX2 对于内存密集型应用程序更有效，而对于密集浮点计算则更少。此外，我们还强调了处理器之间的其他架构差异，即英特尔处理器基于更少的内核和更大的 SIMD 矢量指令，而 TX2 使用更小的 SIMD 寄存器和更多的内核。我们的参考应用程序的性能结果是进一步的确认；事实上，内存密集型内核（例如 LBM 传播和 LQCD Dirac）在 TX2 上实现了更好的性能，而计算密集型 LBM 碰撞在 Intel Skylake 上的性能更好。关于能源效率，我们在运行参考应用程序时分析了处理器的功耗。为了收集功率和能量测量值，我们在英特尔处理器上使用了 RAPL 计数器，而在 TX2 上，我们使用了可用的片上功率传感器。对于 TX2，我们详细描述了如何在应用程序代码中使用功率传感器来测量能耗，并将它们的值与我们测试系统主板上可用的片外传感器读数进行比较。这表明这两个值是一致的。从能源的角度对我们的参考应用进行基准测试，我们表明，对于 LBM 等以浮点为主的计算，TX2 的能源消耗水平与 Skylake 相同，几乎是 Haswell 的一半；另一方面，对于 Dirac 等内存受限应用，TX2 的能效要高得多，所需焦耳是 Skylake 所需焦耳的一半，略多于 Haswell 所需焦耳的三分之一。这证实了 TX2 对于在内存和浮点运算之间表现出良好平衡的应用程序显示出更好的计算和能源效率。如前所述，这是一个有趣的特性，因为一些 HPC 应用程序通常受内存限制，并且许多新兴的科学应用程序（例如，在大数据和人工智能领域）表现出较低的 flop-per-byte 比率值，并且在某些情况下— 接近 1。在旁注中，我们注意到，在我们的分析中，我们使用了常见的 HPC 软件工具——编译器、库等——现在它们在支持 TX2 方面已经达到了很好的成熟度，在通用 Arm 架构，允许执行为其他标准商品处理器开发的几乎开箱即用的代码。

总之，我们的工作表明，TX2是未来高性能计算系统的有效替代解决方案，在计算能力和能源效率方面具有竞争力，在总拥有成本方面也具有潜在优势。对于未来的工作，我们计划还考虑到加速器，如GPU。特别是，我们将对托管TX2处理器和GPU的整个HPC节点的评估感兴趣，这些节点应该很快就会推出。这将允许还考虑到评价和比较不同处理器和加速器之间的节点内通信链路。此外，我们还计划在集群级别上研究TX2的性能和能效，包括节点间通信性能的评估，以及我们的应用程序在多节点系统上的可扩展性。
```

### [13] Porting the LHCb Stack from x86 (Intel) to  aarch64 (ARM) and ppc64le (PowerPC)

```
Promberger L, Clemencic M, Couturier B, et al. Porting the LHCb Stack from x86 (Intel) to aarch64 (ARM) and ppc64le (PowerPC)[J]. The European Physical Journal Conferences, 2019, 214:05016.
```

```
大型强子对撞机正在为即将于2021年开始的第三次大型强子对撞机进行数据选择和处理链的重大变化。有鉴于此，已经启动了几项举措来优化软件堆栈。本文讨论了将LHCb堆栈从x86_64体系结构移植到aarch64和ppc64le体系结构，目的是评估用于高级触发器(HLT)的计算基础设施的性能和成本。这需要移植一个包含500多万行代码的堆栈，并找到LCG提供的外部库的工作版本。在所有软件包中，最大的挑战是越来越多地使用矢量化-因为许多矢量化库专门针对x86体系结构，不支持任何其他体系结构。尽管存在这些挑战，我们还是成功地将LHCb高级触发器代码移植到了aarch64和ppc64le上。这篇文章讨论了软件移植的现状和计划，以及以独立于平台的方式处理代码向量化的LHCb方法。

这项研究是使LHCb协作不仅能够在Intel x86_64计算机上运行他们的Run 3 HLT计算群的第一步，也是在ARM aarch64和PowerPC ppc64le上运行的第一步。在整个工作中，第一个关于跨平台支持向量化将是一个主要问题的分析被证明是正确的。然而，由于这项研究可以证明端口是可行的，并且Intel E5-2630 v4和ARM Cavium ThunderX2之间的性价比差异没有因因素而不同，我们相信继续这项工作将有利于HLT计算群投标的多样性和竞争力。
```

### [14] Supercomputing with commodity CPUs: Are mobile  SoCs ready for HPC

```
Rajovic N, Carpenter P M, Gelado I, et al. Supercomputing with commodity CPUs: Are mobile SoCs ready for HPC?[C]//Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis. 2013: 1-12.
```

```
在20世纪90年代末，强大的经济力量促使商用台式机处理器在高性能计算中得到采用。这种转变是如此有效，以至于2013年6月的TOP500榜单仍然由x86主导。2013年，计算领域最大的大宗商品市场不是个人电脑或服务器，而是移动计算，包括智能手机和平板电脑，其中大部分都是基于ARM的SoC。这导致有人建议，一旦移动SoC提供足够的性能，移动SoC就可以帮助降低HPC的成本。本文对这一问题进行了详细的论述。我们分析了移动SoC性能的趋势，并将其与20世纪90年代的类似趋势进行了比较。我们还介绍了评估移动SoC的性能和效率、部署集群以及评估生产应用程序的网络和可扩展性的经验。总而言之，我们首先回答了移动SoC是否已经为HPC做好了准备。
我们已经证明，移动处理器具有很有前途的特性，使其成为不久的将来高性能计算的候选者。扩展到更多并行节点的应用程序可能会受益于具有竞争力的性能和能效的低成本平台。这些应用要求类似于Bluegene系统的要求。由于移动处理器是由商品组件业务动态驱动的，因此它们拥有更积极的路线图和更快的创新，并受到快速增长的市场的推动，市场对性能的要求越来越高。虽然性能和能耗表明移动SoC正在为HPC做好准备，但在生产系统可行之前，必须解决第6.3节中描述的限制：缺乏ECC保护、互连速度慢、32位地址空间和低等级热封装。所有这些限制都是设计决策，因为HPC和服务器需要缺失的功能，但智能手机和平板电脑不需要。我们鼓励移动SoC供应商考虑在其产品中增加必要的支持。另一个优势是，嵌入式处理器，特别是移动处理器，很可能成为3D存储器封装的早期采用者。这种方法正在考虑用于下一代HPC系统，包括未来的NVIDIA Volta GPU。在移动领域，较高的CPU和内存3D封装成本可以在一个大市场中摊销，而在HPC领域，由于体积较小，更大的成本将转嫁到最终用户身上。一类新的服务器SoC可能会成功，它建立在与移动SoC相同的基本技术之上，并实现缺失的功能。或者，移动供应商可能决定包括面向服务器和HPC市场所需的最小功能集。无论哪种方式，超级计算的成本可能会因为今天的移动SoC的后代而即将下降。
```

### [15] Techniques and tools for measuring energy  efficiency of scientific software applications

```
Abdurachmanov D, Elmer P, Eulisse G, et al. Techniques and tools for measuring energy efficiency of scientific software applications[C]//Journal of Physics: Conference Series. IOP Publishing, 2015, 608(1): 012032.
```

```
近年来，科学高性能计算(HPC)和高吞吐量计算(HTC)的规模显著增加，并对总能耗和成本变得敏感。因此，能源效率已成为高能物理等科学领域的一个重要问题。人们对利用替代架构(如低功耗ARM处理器)来取代传统的Intel x86架构的兴趣日益浓厚。然而，尽管这种解决方案已经成功地用于I/O和内存需求较低的移动应用程序，但尚不清楚它们是否适用于科学计算环境，是否更节能。此外，缺乏工具和经验来推导和比较各种工作负载的架构之间的功耗，并最终支持软件优化以提高能效。为此，我们对在ARM和英特尔架构上运行的HEP应用程序的工作负载进行了多项物理和基于软件的测量，并比较了它们的功耗和性能。我们利用几种分析工具(硬件和软件)来提取不同的用电特征。我们报告了这些测量的结果，以及在开发一套测量技术和分析工具以准确评估科学工作负载的功耗方面获得的经验。

考虑到最近的实验需要大量的计算资源--因此也就是能源--能源效率已经成为HTC的一个主要担忧。考虑到大型强子对撞机目前的要求和成本限制，大型强子对撞机计算是需要高能效设施的一个典型例子。对能源效率的需求促使人们对准确评估HTC系统的不同组件感兴趣，以了解能源是如何以及在哪里消耗的，并提高整体效率。然而，HTC系统是复杂的，由不同的组件组成。在本文中，我们介绍了一些技术和工具，这些技术和工具可以从不同的角度和粒度洞察能量的消耗方式和位置。此外，开源配置工具IgProf已经扩展到运行在64位ARM上，并提供函数级的能量配置功能。使用这些工具和技术，我们还报告了对x86-64和ARMv7处理器的能源性能进行比较的研究，证实了ARMv7对于高效HTC系统的潜力，如果服务器级系统围绕此类芯片构建的话。
```

### [16] Evaluation of mobile ARM-based SoCs for  high performance computing

```
Selinger A, Rupp K, Selberherr S. Evaluation of mobile arm-based socs for high performance computing[C]//Proceedings of the 24th High Performance Computing Symposium. 2016: 1-7.
```

```
当前超级计算机的功耗已成为成功达到亿级的关键限制因素。为了进一步提高能源效率，过去已经提出了使用移动系统芯片(SoCs)。在这项工作中，我们调查了四个配备了不同SoC的开发板，看看它们是否适合高性能计算。每一块板都经过仔细的基准测试，以获得高浮点计算性能、高内存带宽、低延迟和功耗，所有这些都是成功的HPC系统的关键特性。与以前的工作不同，我们还将集成在SoC中的支持OpenCL的图形处理单元包括在我们的基准测试中。我们的基准测试结果表明，移动SoC还没有准备好在HPC中成功采用。虽然理论峰值计算性能和内存带宽表明SoC是现有HPC系统的竞争对手，但实际价值在大多数情况下要低得多。因此，在降低采购成本或提高能效方面，所有SoC都不能为HPC提供有吸引力的选择。

在这项工作中，我们评估了移动SoC对高性能计算环境的适用性。在考虑了原始浮点计算能力、内存带宽和延迟的实际性能后，我们得出结论，移动SoC仅在延迟方面具有竞争力。即使忽略构建基于移动SoC的假想集群所需的额外网络基础设施的成本，SoC上的CPU仍落后于HPC中的大多数现有系统。

目前在移动SoC中向新的ARMv8指令集的迁移预计将通过向64位地址空间的迁移来解决内存容量的限制。此外，通过霓虹灯向量指令预计会有更好的双精度能力。然而，缺乏对纠错码(ECC)主存储器的支持仍将是HPC采用的一个重大障碍。尽管如此，对于无法获得x86许可证的芯片制造商来说，基于ARM的内核仍将是一个有吸引力的选择。
```

### [17] Performance and energy efficiency analysis of HPC  physics simulation applications in a cluster of ARM processors

```
Bez J L, Bernart E E, dos Santos F F, et al. Performance and energy efficiency analysis of HPC physics simulation applications in a cluster of ARM processors[J]. Concurrency and Computation: Practice and Experience, 2017, 29(22): e4014.
```

```
我们分析了使用低功耗的高级RISC机器处理器的非传统集群来执行两个科学并行应用的可行性和能效。为此，我们选择了两个计算和通信成本较高的应用程序：模拟地球物理事件的Ondes3D和模拟天体物理事件的All-Pair N-Body。我们比较和讨论了不同的编译指令和处理器频率的影响，以及它们如何干扰时间到解决方案和能量到解决方案。我们的结果表明，对于高级RISC机器体系结构，通过在编译时正确调整应用程序，我们可以显著减少执行时间和计算模拟所花费的能量。此外，我们观察到，使用双核解决方案的时间缩短了54.14%，解决方案的能源效率提高了53.65%。此外，我们还考虑了两个处理器频率调节器对这些指标的影响。结果表明，节电调速器具有较小的瞬时功耗。然而，它花费更多的时间执行任务，增加了实现解决方案所需的能量。最后，我们用Pareto将实验结果中的能量消耗与执行时间关联起来。这些发现表明，有可能通过调整应用程序和硬件配置来实现能效，从而探索用于高性能计算应用的低性能集群。

在本文中，我们扩展了之前的工作，将能量成本与两个高性能计算应用程序的执行时间关联起来。我们选择了Ondes3D地球物理模拟器和N体问题作为研究的基础。实验是在我们的基于ARM Allwinner A20处理器的8节点实验集群上进行的，并在卢森堡的Grid'5000站点上进行了实验。我们通过调整优化标志和处理器频率来分析不同数量的节点对每个应用程序的影响，以获取我们的测试台和应用程序所能提供的最佳性能。我们已经证明，使用低性能集群来执行Ondes3D和N-Body等科学应用程序是可行的，并在能耗和执行时间之间实现平衡。我们的结果表明，通过正确配置优化指令，可以显著减少应用程序运行时以及它所花费的能量。对于Ondes3D，我们观察到当所有内核都处于活动状态时，执行时间(解决问题的时间)减少了48.19%。在此方案中，还观察到能源到解决方案的收益为46.93%。对于N-Body应用程序，当启用优化标志时，解决方案的时间减少61.09%，并且应用程序在整个集群中执行。此外，与基线相比，能量对溶液的比率也降低了51.94%。考虑到调控器定义的处理器频率，结果显示，使用四核和节电频率管理器时，执行时间最多增加21.37%。虽然处理器的瞬时能耗较小，但由于其工作频率较低，因此执行任务的时间较长。因此，可以理解，只有在处理器空闲或工作负载不大的情况下，频率降低才有用。总结我们的分析，我们表明最初为传统？86平台开发的科学应用程序可以移植到低功耗体系结构上，并呈现低功耗。为此，我们在传统的X86处理器集群上执行Ondes3D应用程序。结果表明，这种方法比在ARM上执行16个进程的速度快7.87倍。然而，该应用程序在ARM集群中达到其解决方案所需的能源远远低于其竞争对手，16个进程的能耗是竞争对手的3.11倍。作为未来的工作，我们希望分析具有16个以上节点的Yggdrasil集群的行为。与ARMv7系列中的其他ARM型号以及较新的ARMv8系列中的ARM A15处理器的比较也被建议作为未来的工作。这一分析可以详细说明嵌入式ARM处理器最近的改进。这项未来的研究还将允许我们检查具有双精度浮点运算支持的霓虹灯单元将如何影响每个节点的性能和能源消耗。将CubieTruck与其他嵌入式平台(如NVIDIA Jetson X1和AMD Opteron A1100)进行比较，并考虑其他功能(例如，CPU和内存特性、网络和磁盘I/O开销)也是很有趣的。
```

### [18] Evaluating ARM HPC clusters for scientific workloads

```
Maqbool J, Oh S, Fox G C. Evaluating ARM HPC clusters for scientific workloads[J]. Concurrency and Computation: Practice and Experience, 2015, 27(17): 5390-5410.
```

```
使用耗电量大的商品服务器构建的现代高性能计算 (HPC) 系统的功耗是实现 Exascale 计算的主要障碍之一。 HPC 社区已经做出了一些努力来鼓励在大规模 HPC 系统中使用低功耗片上系统 (SoC) 嵌入式处理器。这些举措已成功证明了 ARM SoC 在 HPC 系统中的使用，但在为 Exascale 计算提供案例之前，仍然需要分析这些系统在 HPC 平台上的可行性。当前 ARM-HPC 评估的主要缺点包括缺乏对分布式多核系统的性能水平和在 HPC 上运行的大规模应用程序的基准测试的性能水平的详细了解。在本文中，我们对基于 ARM 的 SoC 的服务器和 HPC 基准测试的主要方面的结果进行了全面评估。对于实验，我们构建了一个非常规的 ARM Cortex-A9 集群，称为 Weiser，并运行单节点基准测试（STREAM、Sysbench 和 PARSEC）和多节点科学基准测试（高性能 Linpack (HPL)、NASA Advanced Supercomputing (NAS) Parallel Benchmark 和 Gadget-2)，以便为系统的性能限制提供基准。根据实验结果，我们声称 ARM SoC 的性能在很大程度上取决于内存带宽、网络延迟、应用程序类、工作负载类型以及对编译器优化的支持。在基于服务器的基准测试中，我们观察到，在为数据库事务执行内存密集型基准测试时，x86 对多线程查询处理的性能提高了 12%。但是，ARM 的单核性能功率比提高了四倍，四核提高了 2.6 倍。我们注意到，Java 中模拟的双精度浮点导致性能比 C 中 CPU-bound 基准的性能慢三到四倍。尽管 Intel x86 在面向计算的应用程序中表现稍好，但 ARM 在共享内存基准测试的 I/O 绑定应用程序中表现出更好的可扩展性。我们在 MPJ-Express 运行时中加入了对 ARM 的支持，并对两个广泛使用的消息传递库进行了比较分析。我们在消息传递评估（NBP 和带有 MPJ-Express 和 MPICH 的 Gadget 2）中的集群的网络带宽、大规模应用程序扩展、浮点性能和能效方面获得了类似的结果。我们的研究结果可用于评估基于 ARM 的集群在服务器工作负载和科学工作负载中的能效，并为构建节能 HPC 集群提供指导。

在本文中，我们对基于 ARM 的 SoC 进行了全面评估，并涵盖了服务器和 HPC 基准测试的主要方面。为了提供分析，我们进行了广泛的测量并涵盖了多样化的应用程序和基准测试，包括单节点基准测试（例如，内存带宽（STREAM）、共享内存基准测试（PARSEC）和数据库事务（Sysbench）） ，以及多节点集群基准（例如，HPL、Gadget-2 和 NAS）。根据测量结果，我们发现单节点 ARM SoC 的性能取决于内存带宽、处理器时钟、应用程序类型，而多节点性能在很大程度上取决于网络延迟、工作负载类别以及编译器优化和库使用的优化。在基于服务器的基准测试中，我们观察到在 OLTP 事务等内存密集型基准测试中，英特尔 x86 的多线程查询处理性能水平比 ARM 高 12%。但是，ARM 在单核性能功耗比测试中的表现要好 4 倍，在多核测试中要好 2.6 倍。我们还发现，在 JVM/JRE 中模拟双精度浮点导致 CPU 密集型应用程序中基于 Java 的基准测试的性能要慢三到四倍（与 C 相比）。在共享内存评估期间，英特尔 x86 在 EP 应用程序（例如 Black-Scholes）中显示出明显优于 ARM 的性能优势。然而，对于 I/O 绑定应用程序（例如，Fluidanimate），ARM 显示出更好的 Amdahl 定律缩放效率。我们对使用 NPB 和 Gadget-2 的两个广泛使用的消息传递库（例如 MPICH 和 MPJ-Express）的评估揭示了网络带宽、工作负载类型和消息传递开销对可扩展性、浮点性能、大型规模应用程序和集群的能源效率。我们发现，尽管与商用 HPC 集群相比网络带宽较慢，但我们基于 ARM 的集群实现了 321 MFLOPS/W，略高于 2013 年 11 月 Green500 列表中的第 222 位超级计算机。最后，我们发现当一个ARM 处理器上的 NEON SIMD 浮点单元与手动调整的编译器优化相结合，HPL 的浮点性能比直接（未优化）执行要好 2.5 倍。 ARM 处理器在移动和嵌入式系统市场占有一席之地，通常用于手持设备。然而，这种情况很可能在不久的将来发生改变。从 ARM Cortex-A9 SoC 的多核评估中，我们得出结论，ARM 处理器具有用作轻量级服务器的潜力，并且它们在 I/O 绑定共享内存基准测试中显示出合理的性能水平。基于对 ARM SoC 的分布式内存集群评估，我们能够确认大规模科学模拟的可扩展性以及实现最佳性能水平的不同优化技术。基于 ARM 的 SoC 是数据中心和 HPC 行业对能源效率日益增长的需求的合理解决方案。但是，在 ARM 成为主流之前，仍然存在与软件和硬件支持不佳相关的挑战需要解决。
```

### [19] Characterization and bottleneck  analysis of a 64-bit ARMv8 platform

```
Laurenzano M A, Tiwari A, Cauble-Chantrenne A, et al. Characterization and bottleneck analysis of a 64-bit ARMv8 platform[C]//2016 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). IEEE, 2016: 36-45.
```

```
本文首次全面研究了适用于HPC工作负载的第一个商用64位ARMv8平台-AppliedMicro X-gene的性能、功耗和能耗。我们的研究包括对X基因与HPC系统中常见的其他三个建筑设计点的详细比较。在这些平台上，我们对400多个工作负载进行了仔细的测量，涵盖了不同的应用领域、并行化模型、浮点精度模型和内存强度。我们发现，X-gene的能耗平均是Intel Sandy Bridge的1.2倍，而Sandy Bridge的平均速度是X-gene的2.3倍。精确量化两个平台之间的性能和能源差异的原因是一个重要但具有挑战性的问题，通常通过详细的模拟来解决，这种方法在向上扩展到完整应用程序和广泛的工作负载组合方面的能力有限。相反，本文采用一种称为偏最小二乘(偏最小二乘)路径建模的统计框架来解决这一问题。PLS路径建模使我们能够捕捉复杂的因果关系和难以测量的性能概念，这些概念与体系结构单元和子系统在使用现成的硬件计数器测量改进应用程序性能方面的有效性有关。我们使用偏最小二乘路径模型来量化X-gene和Sandy Bridge在HPC域中性能差异的原因，发现存储子系统的性能是导致这些差异的主要原因。
本文首先对64位ARMv8平台X-gene进行了详细的描述和体系结构瓶颈分析。通过对四种架构设计和数百个应用测试案例的详细分析，我们发现X-gene的性能与Intel Atom大致相当，能耗与Intel Sandy Bridge大致相当。我们还开发了一种称为偏最小二乘路径建模的复杂统计建模技术的新应用，以揭示X-gene上的体系结构瓶颈，揭示了内存子系统是限制高性能计算应用程序的性能和能源消耗的关键体系结构瓶颈之一。
```

### [20] HPC Benchmarking: Scaling Right and  Looking Beyond the Average

```
Radulovic M, Asifuzzaman K, Carpenter P, et al. HPC benchmarking: scaling right and looking beyond the average[C]//European Conference on Parallel Processing. Springer, Cham, 2018: 135-146.
```

```
设计一个平衡的HPC系统需要了解主要的性能瓶颈。到目前为止，还没有成熟的方法来统一评估HPC系统和工作负载，以量化主要的性能瓶颈。在本文中，我们在一个生产HPC平台上运行了7个生产HPC应用程序，并分析了关键的性能瓶颈：Flop性能和内存带宽拥塞，以及对向外扩展的影响。我们表明，结果在很大程度上取决于执行进程的数量和测量的粒度。因此，我们主张在应用程序套件中指导选择实验的代表性规模。此外，我们还建议用低、中、重度利用率的时间比例来表示FLOPS的性能和内存带宽。我们表明，这提供了比平均水平更准确和更具可操作性的证据。

清楚地了解HPC系统的性能因素和瓶颈，对于设计具有最佳功能和合理成本的HPC基础设施至关重要。这种看法只能通过仔细分析现有的高性能计算系统及其工作负载的执行情况来实现。在执行生产HPC应用程序时，我们的研究结果表明，HPC应用程序的性能指标强烈依赖于执行进程的数量。我们认为，HPC应用程序套件必须指定进程数量的窄范围，才能使结果代表真实世界的应用程序使用。此外，我们还发现，对性能指标和瓶颈的平均测量可能具有很强的误导性。相反，我们建议将性能度量定义为应用程序使用最大持续值的某些部分的执行时间的百分比。总体而言，我们认为这项研究为准确衡量关键性能因素及其对整体HPC性能的影响提供了新的指导方针。
```

### [21] Advanced Performance Analysis of HPC Workloads on  Cavium ThunderX

```
Calore E, Mantovani F, Ruiz D. Advanced performance analysis of HPC workloads on Cavium ThunderX[C]//2018 International Conference on High Performance Computing & Simulation (HPCS). IEEE, 2018: 375-382.
```

```
在过去5年中，人们对基于ARM的平台作为高性能计算解决方案的兴趣显著增加。在这篇文章中，我们展示了，与早期的先锋测试相比，几种应用性能分析技术现在也可以应用于基于ARM的SoC。为了展示现有工具提供的可能性，我们提供了一个对Lattice Boltzmann HPC产品代码的分析作为示例，该代码针对几种架构进行了高度优化，现在也移植到了ARMv8。我们在一个基于生产硅片Cavium CN8890 SoC的系统上进行了测试。特别是，作为性能分析工具，我们采用了Extrae和Paraver，利用了我们最初为ThunderX平台开发的PAPI支持，现在也可以在上游使用。本文的贡献有两方面：首先，我们证明了独立于CPU提供商的标准HPC平台上可用的性能分析工具目前也可用于ARM SoC；其次，我们针对该平台实际优化了HPC应用程序，显示了与其他体系结构的相似之处。

在本文中，我们总结了在巴塞罗那超级计算中心为访问Cavium ThunderX CN8890 SoC的硬件性能计数器所做的工作，目的是在该平台上的标准HPC性能分析工具中利用这些计数器。所有生成的补丁现在都可以在各自项目的上游版本中使用。多亏了简单的微基准，我们已经能够识别出不符合其他ARM平台的计数器，如Tab中所述。I.尤其是PAPI_VEC_INS计数器目前在此架构上不应被认为是可信的。通过在Cavium ThunderX节点上的工作，我们展示了在ARM SoC上也可以利用其他架构(如Extrae和Paraver)上已经开发和使用的工具来执行高级性能分析，这些工具利用PAPI库来读取硬件性能计数器。特别是，我们已经展示了如何利用这些工具，分析了一个实际的HPC应用程序，该应用程序实现了一个在Cavium ThunderX上运行的、由INFN和Ferrara大学开发的Lattice Boltzmann模型。多亏了这一分析，我们能够识别导致此应用程序在Cavium ThunderX体系结构上性能提高的低效率(即，传播带宽增加了62%)。进一步的研究可能会导致其他优化，以获得更好的结果。最终，我们可以声明，在此平台上，现在可以执行标准HPC计算机上可用的大多数性能分析。我们还表明，对于本文中考虑的流体力学应用程序，针对其他多核架构(如Intel Knl)引入的优化也可以在ARM SoC(如Cavium ThunderX)上受益。我们计划将这项工作扩展到ThunderX芯片的第二个版本，预计该芯片将在HPC市场得到广泛采用，此外，我们还希望能够访问嵌入在此SoC中的非标准电源相关寄存器，就像访问其他体系结构所做的那样。使用PAPI读取功率数据的可能性也将使精细的能量分析成为可能，而不需要外部功率表。
```

### [22] A performance analysis of the first generation of  HPC‐optimized Arm processors

```
McIntosh‐Smith S, Price J, Deakin T, et al. A performance analysis of the first generation of HPC‐optimized Arm processors[J]. Concurrency and Computation: Practice and Experience, 2019, 31(16): e5110.
```

```
在这篇文章中，我们展示了Isambard的性能结果，这是第一台基于ARM CPU的生产型超级计算机，这些CPU已经针对高性能计算进行了优化。Isambard是第一个Cray XC50“侦察”系统，将Cavium ThunderX2基于ARM的CPU与Cray‘s Aries互连结合在一起。整个Isambard系统将于2018年夏天交付，届时它将包含1万多个ARM核心。在这项工作中，我们展示了2018年3月升级到B0测试版硅片的8个早期访问节点的节点级性能结果。我们提供了ThunderX2与主流CPU(包括Intel Skylake和Broadwell以及Xeon Phi)的节点级基准测试结果。我们专注于一系列对英国国家HPC服务Archer以及Isambard项目合作伙伴和更广泛的HPC社区至关重要的应用程序和迷你应用程序。我们还比较了可用于ARM的三个主要软件工具链的性能：Cray的CCE、ARM版本的Clang/Flang/LLVM和GNU。

本文提供的结果表明，基于ARM的处理器现在能够提供与现有供应商提供的最先进产品相媲美的性能水平，同时显著提高每美元的性能。我们的大多数基准测试开箱即可成功编译和运行，无需特定于体系结构的代码调优即可实现高性能。这代表着HPC ARM生态系统成熟的一个重要里程碑，这些处理器现在可以被视为未来采购的可行竞争者。未来的工作将使用完整的Isambard系统来评估在ThunderX2处理器上大规模运行的生产应用程序。我们在这篇论文中没有提到能源效率。我们早期的观察表明，ThunderX2的能效与我们测试的x86 CPU大致相同。这并不令人惊讶--对于给定的制造技术，一次翻转将占用一定数量的焦耳，而在芯片上移动一个字节一定距离也将消耗一定数量的能量。没有魔力，当大部分能量都花在移动数据和执行数值运算时，指令集体系结构对能效的影响很小。总体而言，这些结果表明，针对HPC进行了优化的基于ARM的服务器CPU现在是真正的生产系统选项，提供了与同类最佳CPU相媲美的性能，同时可能提供诱人的性价比优势。
```

### [23] SoC-based computing infrastructures for scientific applications and commercial services: Performance and economic evaluations

```
D’Agostino D, Quarati A, Clematis A, et al. SoC-based computing infrastructures for scientific applications and commercial services: Performance and economic evaluations[J]. Future Generation Computer Systems, 2019, 96: 11-22.
```

```
从传统的高性能计算中心到云数据中心，能源消耗是目前运营计算基础设施中最相关的问题之一。低功耗片上系统(SoC)体系结构最初是在移动和嵌入式技术的背景下发展起来的，由于其日益增长的计算性能以及相对较低的成本和功耗需求，对科学和工业应用也越来越有吸引力。在本文中，我们考察了最具代表性的SoC在计算密集型N-Body基准测试、简单的基于深度学习的应用和来自分子生物学领域的实际应用中的性能。目标是评估与现有基础设施中采用的传统服务器级架构相比，它们能够实现的科学和商业目的的解决方案的时间、能量到解决方案和经济方面的权衡。

本文对在计算基础设施中采用低功耗片上系统的性能和经济方面进行了分析。从两个基准测试，即广泛使用的N-Body算法和基于深度学习的应用程序出发，我们讨论了最先进的低功耗SoC体系结构与配备现有计算基础设施的传统服务器级CPU和GPU相比所能达到的性能。然后，我们将重点转移到评估有趣的原始、能量和计算数字是否也适用于现实生活中的应用场景。事实上，SoC是运行许多科学和商业应用程序的一种有趣的替代方案。在本文中，我们分析了一个场景，其中SME愿意使用基于SoC的基础设施来提供基于来自分子生物学领域的真实生活应用的服务。需要注意的是，将高端商业/HPC服务器与基于来自移动和嵌入式世界的低功耗SoC的主板进行比较可能被认为是不公平的，但所提供的结果也评估了对于耗时的应用，如NGS数据分析，从解决方案的时间到解决方案的能量到解决方案的经济方面的折衷而言，使用低功耗架构是一种可行的选择。这项工作的未来发展是双重的。我们将从一个方面评估来自具有不同需求的应用领域的其他用例。特别是，我们正在考虑将这种低功耗架构与边缘计算范式相结合，用于物联网应用和制药行业，通过对蛋白质-化学物质相互作用的计算机模拟来开发新药。此外，我们计划通过在总拥有成本中包括更广泛的元素，例如网络互连、冷却和开发能够利用如此多的低功耗计算节点的应用程序的成本，来扩展在计算基础设施中采用基于SoC的集群的分析。这方面与并行计算社区的研究工作部分重叠，为亿级计算铺平了道路。
```

### [24] 借势 ARM 挑战 Intel？一窥中国芯发展现状

```
铁流. 借势 ARM 挑战 Intel? 一窥中国芯发展现状[J]. 微型计算机, 2017 (15): 104-106.
```

```
国内将 ARM 处理器引入大规模 HPC 集群的时间较晚，发展较好的 ARM 芯片厂商包括申微、天津飞腾、华芯通和华为等。ARM 面向 HPC 的相关研究在近五年内才逐渐增多，这些工作对本文进行 ARM 系统的性能评测、应用移植和优化研究具有很大启发。
```

### [25] 基于ARM V8 平台的多维FFT 实现与优化研究

```
陈暾, 李志豪, 贾海鹏, 等. 基于 ARM V8 平台的多维 FFT 实现与优化研究[J]. 计算机学报, 2019, 11.
```

```
ARM V8 是首款支持 64 位指令集的 ARM 处理器架构，其计算能力获得了极大提升，应用领域也更加广泛。FFT（快速傅里叶变换）是用于计算离散傅里叶变换（DFT）或其逆运算的快速算法，它广泛应用于工程，科学和数学计算。到目前为止，鲜有基于 ARM 平台的高性能 FFT 算法的实现和优化，然而，随着 ARM V8 处理器应用的日益广泛，研究 FFT算法在 ARM 平台上高性能实现日益重要。本文在 ARM V8 平台上实现和优化了一个高性能的多维 FFT 算法库：PerfFFT，通过 FFT 蝶形网络优化、蝶形计算优化、蝶形自动生成、SIMD 优化、内存对齐、Cache-aware 的分块算法和高效转置等优化方法的应用，显著提升了 FFT 算法的性能。实验结果表明，PerfFFT 相比目前应用最为广泛的开源 FFT 库 FFTW3.3.6 实现了 10%~591%的性能提升，而相比 ARM 高性能商业库 ARM Performance Library 实现了 13%~44%的性能提升。

本文在实现多维 FFT 变换的基础上，提出了蝶形网络优化、蝶形计算优化、蝶形自动生成、SIMD优化、内存对齐、Cache-Aware 的分块算法和高效转置算法等优化方法，实现了一个 ARM V8 平台上的高性能的多维 FFT 库：PerfFFT。与现有的高性能 FFT 软件库 FFTW、ARMPL 相比，PerfFFT 性能都明显高于这两个库的性能。这不仅实现了提升ARM V8 平台 FFT 软件库性能的目标，而且为 ARM V8 平台上程序优化提供了新的思路。未来的主要工作将从双精度 FFT 算法的实现和优化、三维 FFT减少 TLB 缺失率优化，两个首要的入手点，最后，为 FFT 软件库搭建自适应框架也未来一个重要的工作，我们着眼于手工优化和自适应优化技术相结合的方式，进一步提升 FFT 算法库的性能。
```

### [26] 一种 ARM 处理器面向高性能计算的性能评估

```
王一超, 廖秋承, 左思成, 等. 一种 ARM 处理器面向高性能计算的性能评估[J]. 计算机科学, 2019, 46(8): 95-99.
```

```
上海交通大学网络信息中心的王一超等人在 2019 年对一款面向 HPC 的ARM 处理器做了较为全面的性能评估。该文章从微架构层面选取了 HPL 和STREAM 等基准测试指标，从应用层面选取了 CloverLeaf、TeaLeaf、SNAP 和Neutral 四款科学应用进行 ARM 处理器性能评估，同时将性能与主流商用的 Xeno处理器进行了比较。结果表明 ARM 处理器在“绿色计算”领域具有竞争力，但在计算密集型和随机访存型的应用支持上仍需要更多的改进。
```

### [27] 飞腾处理器与商用处理器性能比较

```
方建滨, 杜琦, 唐滔, 等. 飞腾处理器与商用处理器性能比较[J].  计算机工程与科学, 2019, 41(1): 1-8.
```

```
国防科技大学的方建滨等人类似地从微基准测试和应用层面两方面深入分析了国产基于 ARM 架构的飞腾 FT-1500A 型和商用 Intel 至强处理器的性能差异，并研究了将一个开源代码移植到两个系统的方法，讨论了在这两个系统的单核和多核性能，并依据实验结果提出了优化建议。作者认为 FT-1500A 飞腾处理器已具备良好的生态基础（易用的操作系统、多种编译器和易用的工具链），这使得移植典型科学计算应用变得简单可行，此外还指出了此款 ARM 处理器在性能上的不足之处。
```

### [28] An empirical study of hpc workloads on huawei kunpeng 916 processor

```
Wang Y C, Chen J K, Li B R, et al. An empirical study of hpc workloads on huawei kunpeng 916 processor[C]//2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS). IEEE, 2019: 360-367.
```

```
基于ARM的服务器处理器在高性能计算(HPC)方面获得了发展势头。虽然不是专门为HPC设计的，但华为鲲鹏916处理器拥有32个ARMv8内核，对HPC工作负载很有吸引力。然而，它的潜力仍然未知。为了透彻地了解其潜力，我们分三个步骤进行了系统的评估：1)三个著名的基准测试(HPL、STREAM和LMbench)；2)三个典型的科学内核(SpMV、N-Body和GEMM)；3)三个广泛使用的迷你应用程序(TeaLeaf、Neual和SNAP)和一个真实世界的应用程序GTC-P。我们将鲲鹏916与Intel Xeon E5-2680v3/4(Haswell/Broadwell)的性能结果进行了比较。评估结果表明，鲲鹏916的内存带宽高于两个Intel处理器，因此可以在运行内存受限的高性能计算应用程序时获得令人信服的性能。
```

### Migrating Software from x86 to ARM Architecture: An Instruction Prediction Approach

```
Ford B W, Qasem A, Tesic J, et al. Migrating Software from x86 to ARM Architecture: An Instruction Prediction Approach[C]//2021 IEEE International Conference on Networking, Architecture and Storage (NAS). IEEE Computer Society, 2021: 1-6.
```

````
几十年来，Intel和AMD支持的x86架构一直是软件开发的主要目标。最近，ARM通过同时展示高性能和低功耗，已经巩固了自己作为一个高度竞争和有前途的CPU架构。在可预见的未来，大量的软件将完全迁移到ARM架构，或者同时支持x86和ARM。然而，从x86到ARM的软件移植并不是微不足道的，原因有很多。首先，为新体系结构编写解决所有兼容性问题的代码非常耗时。其次，特定的硬件(如ARM芯片)和支持工具包(如库和编译器)可能对开发人员来说并不容易获得，这将延迟移植过程。第三，在产品芯片上测试之前，很难预测软件的性能。在本文中，我们试图通过提出一种指令预测方法来解决这些挑战，该方法可以从现有的x86-64可执行文件中自动生成AARCH64代码。虽然生成的代码可能不能直接执行，但它为开发人员提供了一个廉价而高效的解决方案，以便在实际构建、部署和测试基于arm的CPU上的代码之前，评估某些运行时指标。实验结果表明，使用预测方法生成的AARCH64指令能够获得较高的双语评估代研究(BLEU)分数。这表明生成的可执行文件和本地移植的AARCH64软件之间的质量匹配。
````

### Simplifying heterogeneous migration between x86 and ARM machines

```
Mavrogeorgis N. Simplifying heterogeneous migration between x86 and ARM machines[J]. arXiv preprint arXiv:2112.01189, 2021.
```

```
异构计算是在单个工作流中部署多种类型的处理元素，并允许每种处理元素执行最适合的任务的策略。为了充分利用异构的力量，我们希望能够动态调度部分代码，并在运行时在体系结构之间迁移流程。此外，迁移还包括转换流程的执行状态，这会带来巨大的开销，从而抵消了迁移带来的好处。我的博士学位的目标是研究允许应用程序在共享编程模型下运行在异构核心上的技术，并解决在这些高度不同的系统上运行的进程之间创建统一地址空间的一般问题。这将极大地简化迁移过程。我们将从研究x86和ARM二进制文件之间的通用堆栈布局开始，重点关注这两种广泛传播的体系结构，然后我们将尝试推广到其他更多样化的执行环境。最重要的是，将对上述努力的性能和能源效率与当前方法进行比较。

本文概述了我们提出的简化异构ISA迁移的方法。我们的计划是提出在进程之间创建统一地址空间的解决方案，同时消除运行时状态转换的开销。初步结果表明，通过在x86-64和Aarch64目标之间使用相同的ABI来执行类似的堆栈布局，不会显著降低性能，但它为实际创建相同的堆栈布局铺平了道路。最终目标是扩展这项工作，以简化迁移到各种目标(除了x86-64和ARMv8)的可移植性。
```

### Porting Applications to Arm-based Processors

```
Brank B, Nassyr S, Pouyan F, et al. Porting Applications to Arm-based Processors[C]//2020 IEEE International Conference on Cluster Computing (CLUSTER). IEEE, 2020: 559-566.
```

```
基于arm的服务器处理器越来越多地用于构建大规模并行HPC系统。这就需要将HPC应用程序移植到这样的体系结构中，并收集有关性能优势和挑战的更多知识。在这篇文章中，我们报告了在Jülich超级计算中心(JSC)持续努力将应用程序移植到基于arm的平台期间所取得的经验。本文在不同的基于arm的节点架构和基于x86的架构上探讨了这些应用程序的性能，以供参考。
选取了四个应用，
```

###  Changing Trends in Computer Architecture: A Comprehensive Analysis of ARM and x86 Processors

```
Gupta K, Sharma T. Changing Trends in Computer Architecture: A Comprehensive Analysis of ARM and x86 Processors[J]. 2021.
```

```

```

### 汇编语言差异比较——从X86到ARM

```
过怡,刘文芝.汇编语言差异比较——从X86到ARM[J].江苏科技信息,2019,36(22):39-42.
```

```
文章从5个方面比较了教学中普遍采用的两种CPU——X86 CPU和ARM CPU的差异。X86作为典型的 CISC计算机汇编语言，指令系统复杂，主要应用于通用计算机中。ARM采用嵌入式系统中广泛采用的RISC结构，多应用于嵌入式领域。只有采用比较的学习方法才能更好地掌握不同处理器的特点及应用需求，更有利于实际的系统开发。

X86 CPU 采用冯诺依曼体系结构，指令和数据存储在同一个存储器中，指令和数据只能采用相同的宽度，并且总线在同一时刻只能传递一种内容，指令或者数据，速度受限。ARM CPU 采用哈佛体系结构，指令和数据采用不同的存储器，因此，指令和数据可以采用不同的数据宽度，并且总线操作较快。X86CPU 是采用 CISC 指令集，拥有丰富的指令，每一代新的 CPU 为了保持对前期产品的兼容，会在保留原有指令的基础上扩展新的指令，导致指令系统越来越复杂，但是程序员有更多可选择的指令。ARM CPU采用 RISC 指令集，只保留常用的指令，指令结构简单，程序员可选择的指令也少。随着高级语言不断发展，作为低级语言的汇编语言的应用场合逐渐减少，但是在操作系统的部分内核代码，无操作系统的启动代码，软件系统中对运行效率有要求的部分代码，仍然采用汇编语言编写，尤其在嵌入式领域汇编还是有着重要的作用，因此，有效地掌握和使用不同CPU的汇编语言有着重要的实际意义。
```

### 面向ARM架构的HPC系统性能评测及应用移植优化

```
戈孜荣. 面向ARM架构的HPC系统性能评测及应用移植优化[D].兰州大学,2020.DOI:10.27204/d.cnki.glzhu.2020.001360
```

```

```

###  Comparative benchmarking of the first generation of hpc-optimised arm processors on isambard

```
McIntosh-Smith S, Price J, Deakin T, et al. Comparative benchmarking of the first generation of hpc-optimised arm processors on isambard[J]. Cray user group, 2018, 5.
```

```
```

### Porting the LCG software stack to the ARM architecture

```
Marik M. Porting the LCG software stack to the ARM architecture[R]. 2019.
```

```
```

